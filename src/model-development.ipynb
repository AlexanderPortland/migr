{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a6f5715-4d67-473f-911f-8300c4bd0a10",
   "metadata": {},
   "source": [
    "# Splitting, Preprocessing and Model Development\n",
    "This notebook is used for:\n",
    "1. [Introduce Lagged Features](#1.-Introduce-Lagged-Features)\n",
    "2. [Dataset Splitting](#2.-Dataset-Splitting)\n",
    "3. [General Model Development Functions](#3.-General-Model-Development-Functions)\n",
    "4. [Model Training](#4.-Model-Training)\n",
    "\n",
    "### Declaring Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95c2e3ee-462e-4de4-beb8-d24530ccbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import sklearn\n",
    "import time\n",
    "import datetime\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7821379-13ed-4b03-bc52-81fa1ce05c15",
   "metadata": {},
   "source": [
    "### Color Palette & Typeface Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9479ba4-963a-4304-8c69-00770f57d474",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW = '#F2DC5D'\n",
    "GREEN = '#9BC53D'\n",
    "DARK_GREEN = '#597222'\n",
    "RED = '#C3423F'\n",
    "LIGHT_BLUE = '#2596BE'\n",
    "GRAY = '#666666'\n",
    "\n",
    "AXIS_SIZE = 12\n",
    "TITLE_SIZE = 16\n",
    "DESCRIPTION_SIZE = 9\n",
    "FIGURE_SIZE = (10*2/3,6*2/3)\n",
    "\n",
    "RANDOM_STATE = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcf6c7b-3b5d-491c-84fe-e489b481e4e0",
   "metadata": {},
   "source": [
    "### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70f11f5f-4aa7-42d2-a564-9792f8a58c35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizen</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>GENCONV</th>\n",
       "      <th>HUMSTAT</th>\n",
       "      <th>SUB_PROT</th>\n",
       "      <th>REJECTED</th>\n",
       "      <th>TOTAL_POS</th>\n",
       "      <th>TOTAL_APPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221109</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221110</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221111</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221112</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221113</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7213806 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        citizen  sex     age geo TIME_PERIOD  GENCONV  HUMSTAT  SUB_PROT  \\\n",
       "0            AD    F     UNK  AT     2008-Q1        0        0         0   \n",
       "1            AD    F     UNK  AT     2008-Q2        0        0         0   \n",
       "2            AD    F     UNK  AT     2008-Q3        0        0         0   \n",
       "3            AD    F     UNK  AT     2008-Q4        0        0         0   \n",
       "4            AD    F     UNK  AT     2009-Q1        0        0         0   \n",
       "...         ...  ...     ...  ..         ...      ...      ...       ...   \n",
       "7221109      ZW  UNK  Y_LT14  UK     2019-Q3        0        0         0   \n",
       "7221110      ZW  UNK  Y_LT14  UK     2019-Q4        0        0         0   \n",
       "7221111      ZW  UNK  Y_LT14  UK     2020-Q1        0        0         0   \n",
       "7221112      ZW  UNK  Y_LT14  UK     2020-Q2        0        0         0   \n",
       "7221113      ZW  UNK  Y_LT14  UK     2020-Q3        0        0         0   \n",
       "\n",
       "         REJECTED  TOTAL_POS  TOTAL_APPS  \n",
       "0               0          0           0  \n",
       "1               0          0           0  \n",
       "2               0          0           0  \n",
       "3               0          0           0  \n",
       "4               0          0           0  \n",
       "...           ...        ...         ...  \n",
       "7221109         0          0           0  \n",
       "7221110         0          0           0  \n",
       "7221111         0          0           0  \n",
       "7221112         0          0           0  \n",
       "7221113         0          0           0  \n",
       "\n",
       "[7213806 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/final.csv', dtype={'citizen': 'string', 'sex': 'string', 'age': 'string', 'decision': 'string', 'geo': 'string', 'TIME_PERIOD': 'string', 'GENCONV': \"Int64\", 'HUMSTAT': \"Int64\", 'SUB_PROT': \"Int64\", 'REJECTED': \"Int64\", 'TOTAL_POS': \"Int64\", 'TOTAL_APPS': \"Int64\", \"POS_RATE\": \"Float64\"}, keep_default_na=False, na_values=['nan'])\n",
    "\n",
    "##remove partial 2023-Q3 Data\n",
    "df = df[df[\"TIME_PERIOD\"] != \"2023-Q3\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951da0b6-f7f6-4384-846a-06f744c7f656",
   "metadata": {},
   "source": [
    "## 1. Introduce Lagged Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d06767ee-3b22-46a7-8c6c-23f2a35fa952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizen</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>GENCONV</th>\n",
       "      <th>HUMSTAT</th>\n",
       "      <th>SUB_PROT</th>\n",
       "      <th>REJECTED</th>\n",
       "      <th>TOTAL_POS</th>\n",
       "      <th>TOTAL_APPS</th>\n",
       "      <th>TOTAL_POS - lag 1 quarter</th>\n",
       "      <th>TOTAL_POS - lag 2 quarters</th>\n",
       "      <th>TOTAL_POS - lag 3 quarters</th>\n",
       "      <th>TOTAL_POS - lag 4 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 1 quarter</th>\n",
       "      <th>TOTAL_APPS - lag 2 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 3 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 4 quarters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2010-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221109</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221110</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221111</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221112</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221113</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6731478 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        citizen  sex     age geo TIME_PERIOD  GENCONV  HUMSTAT  SUB_PROT  \\\n",
       "4            AD    F     UNK  AT     2009-Q1        0        0         0   \n",
       "5            AD    F     UNK  AT     2009-Q2        0        0         0   \n",
       "6            AD    F     UNK  AT     2009-Q3        0        0         0   \n",
       "7            AD    F     UNK  AT     2009-Q4        0        0         0   \n",
       "8            AD    F     UNK  AT     2010-Q1        0        0         0   \n",
       "...         ...  ...     ...  ..         ...      ...      ...       ...   \n",
       "7221109      ZW  UNK  Y_LT14  UK     2019-Q3        0        0         0   \n",
       "7221110      ZW  UNK  Y_LT14  UK     2019-Q4        0        0         0   \n",
       "7221111      ZW  UNK  Y_LT14  UK     2020-Q1        0        0         0   \n",
       "7221112      ZW  UNK  Y_LT14  UK     2020-Q2        0        0         0   \n",
       "7221113      ZW  UNK  Y_LT14  UK     2020-Q3        0        0         0   \n",
       "\n",
       "         REJECTED  TOTAL_POS  TOTAL_APPS  TOTAL_POS - lag 1 quarter  \\\n",
       "4               0          0           0                          0   \n",
       "5               0          0           0                          0   \n",
       "6               0          0           0                          0   \n",
       "7               0          0           0                          0   \n",
       "8               0          0           0                          0   \n",
       "...           ...        ...         ...                        ...   \n",
       "7221109         0          0           0                          0   \n",
       "7221110         0          0           0                          0   \n",
       "7221111         0          0           0                          0   \n",
       "7221112         0          0           0                          0   \n",
       "7221113         0          0           0                          0   \n",
       "\n",
       "         TOTAL_POS - lag 2 quarters  TOTAL_POS - lag 3 quarters  \\\n",
       "4                                 0                           0   \n",
       "5                                 0                           0   \n",
       "6                                 0                           0   \n",
       "7                                 0                           0   \n",
       "8                                 0                           0   \n",
       "...                             ...                         ...   \n",
       "7221109                           0                           0   \n",
       "7221110                           0                           0   \n",
       "7221111                           0                           0   \n",
       "7221112                           0                           0   \n",
       "7221113                           0                           0   \n",
       "\n",
       "         TOTAL_POS - lag 4 quarters  TOTAL_APPS - lag 1 quarter  \\\n",
       "4                                 0                           0   \n",
       "5                                 0                           0   \n",
       "6                                 0                           0   \n",
       "7                                 0                           0   \n",
       "8                                 0                           0   \n",
       "...                             ...                         ...   \n",
       "7221109                           0                           0   \n",
       "7221110                           0                           0   \n",
       "7221111                           0                           0   \n",
       "7221112                           0                           0   \n",
       "7221113                           0                           0   \n",
       "\n",
       "         TOTAL_APPS - lag 2 quarters  TOTAL_APPS - lag 3 quarters  \\\n",
       "4                                  0                            0   \n",
       "5                                  0                            0   \n",
       "6                                  0                            0   \n",
       "7                                  0                            0   \n",
       "8                                  0                            0   \n",
       "...                              ...                          ...   \n",
       "7221109                            0                            0   \n",
       "7221110                            0                            0   \n",
       "7221111                            0                            0   \n",
       "7221112                            0                            0   \n",
       "7221113                            0                            0   \n",
       "\n",
       "         TOTAL_APPS - lag 4 quarters  \n",
       "4                                  0  \n",
       "5                                  0  \n",
       "6                                  0  \n",
       "7                                  0  \n",
       "8                                  0  \n",
       "...                              ...  \n",
       "7221109                            0  \n",
       "7221110                            0  \n",
       "7221111                            0  \n",
       "7221112                            0  \n",
       "7221113                            0  \n",
       "\n",
       "[6731478 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#****************************************************re-sort dataframe****************************************************\n",
    "\n",
    "sort_order = ['citizen', 'sex', 'age', 'geo', 'TIME_PERIOD']\n",
    "df = df.sort_values(by =sort_order) \n",
    "\n",
    "#*********************************************create sequential list of quarters****************************************************\n",
    "\n",
    "quarters = []\n",
    "for i in range(2008, 2024):\n",
    "    quarters.append(str(i) + \"-Q1\")\n",
    "    quarters.append(str(i) + \"-Q2\")\n",
    "    quarters.append(str(i) + \"-Q3\")\n",
    "    quarters.append(str(i) + \"-Q4\")\n",
    "\n",
    "#****************************************************lagged features****************************************************\n",
    "\n",
    "QUARTERS_OF_LAG = (4 * 1)\n",
    "\n",
    "def add_lagged_features(df, features, maintained_columns, QUARTERS_OF_LAG):\n",
    "    quarters = np.unique(df[\"TIME_PERIOD\"])\n",
    "    def lagged_features(target_var, lag_count, unit):\n",
    "        lagged = pd.DataFrame()\n",
    "        columns = []\n",
    "        for i in range(1, lag_count + 1):\n",
    "            lagged = pd.concat([lagged, target_var.shift(i)], axis=1)\n",
    "            name = target_var.name\n",
    "            if (i == 1):\n",
    "                columns.append(name + \" - lag \" + str(i) + \" \" + str(unit))\n",
    "            else:\n",
    "                columns.append(name + \" - lag \" + str(i) + \" \" + str(unit) + \"s\")\n",
    "        lagged.columns = columns\n",
    "        return lagged.astype('Int64')\n",
    "\n",
    "    #introduce lag for each feature\n",
    "    df_lagged = df\n",
    "    for f in features:\n",
    "        df_lagged = pd.concat([df_lagged, lagged_features(df[f], QUARTERS_OF_LAG, \"quarter\")], axis=1)\n",
    "\n",
    "    #remove all features with less than the lag amount of historical data\n",
    "    #df_lagged = df_lagged[df_lagged.eq()]\n",
    "    for i in range(0, QUARTERS_OF_LAG):\n",
    "        shift_eq = df_lagged.eq(df_lagged.shift())\n",
    "        keep = shift_eq[maintained_columns[0]]\n",
    "        for j in range(1, len(maintained_columns)):\n",
    "            keep = keep & shift_eq[maintained_columns[j]]\n",
    "        df_lagged = df_lagged[keep]\n",
    "        #print(\"lagged i\" + str(i) + \" of \" + str(QUARTERS_OF_LAG))\n",
    "    \n",
    "    return df_lagged\n",
    "\n",
    "df_lagged = add_lagged_features(df, [\"TOTAL_POS\", \"TOTAL_APPS\"], ['citizen', 'age', 'sex', 'geo'], QUARTERS_OF_LAG)\n",
    "\n",
    "df_lagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1642eba7-0aea-4c6e-a0b5-2a59347fc933",
   "metadata": {},
   "source": [
    "### Lagged Feature Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b22df96e-8f75-412b-9644-c610f82df667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] testing lagging function\n",
      "\t[+] basic lag tests passed\n",
      "\t[+] tests with shared times passed\n",
      "\t[+] tests with multiple start and end dates passed\n",
      "\t[+] \u001b[42mPASSED ALL\u001b[0m lagging tests\n"
     ]
    }
   ],
   "source": [
    "#***********************************************testing equivalence function****************************************************\n",
    "def equivalent_dfs(df1, df2):\n",
    "    return (df1.reset_index(drop=True) == df2.reset_index(drop=True)).all().all()\n",
    "\n",
    "#****************************************************lagging testing****************************************************\n",
    "print(\"[*] testing lagging function\")\n",
    "#simple tests\n",
    "tdf0_data = [['AR', 1, 1], ['AR', 2, 2], ['AR', 3, 3], ['AR', 4, 4], ['AR', 5, 5]]\n",
    "tdf0 = pd.DataFrame(data=tdf0_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf1_data = [['AR', 2, 2, 1], ['AR', 3, 3, 2], ['AR', 4, 4, 3], ['AR', 5, 5, 4]]\n",
    "tdf1 = pd.DataFrame(data=tdf1_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf2_data = [['AR', 3, 3, 2, 1], ['AR', 4, 4, 3, 2], ['AR', 5, 5, 4, 3]]\n",
    "tdf2 = pd.DataFrame(data=tdf2_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "tdf3_data = [['AR', 4, 4, 3, 2, 1], ['AR', 5, 5, 4, 3, 2]]\n",
    "tdf3 = pd.DataFrame(data=tdf3_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters', 'val - lag 3 quarters'])\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 1), \n",
    "                      tdf1), \"basic lag test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 2), \n",
    "                      tdf2), \"basic lag test failed, shift=2\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 3), \n",
    "                      tdf3), \"basic lag test failed, shift=3\"\n",
    "print(\"\\t[+] basic lag tests passed\")\n",
    "\n",
    "#more advanced tests\n",
    "tdf4_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "             ['NZ', 1, 11], ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15]]\n",
    "tdf4 = pd.DataFrame(data=tdf4_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf5_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "             ['NZ', 2, 12, 11], ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14]]\n",
    "tdf5 = pd.DataFrame(data=tdf5_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf6_data = [['AU', 3, 3, 2, 1], ['AU', 4, 4, 3, 2], ['AU', 5, 5, 4, 3],\n",
    "             ['NZ', 3, 13, 12, 11], ['NZ', 4, 14, 13, 12], ['NZ', 5, 15, 14, 13]]\n",
    "tdf6 = pd.DataFrame(data=tdf6_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf4, [\"val\"], ['citizen'], 1), \n",
    "                      tdf5), \"lag with shared times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf4, [\"val\"], ['citizen'], 2), \n",
    "                      tdf6), \"lag with shared times test failed, shift=2\"\n",
    "print(\"\\t[+] tests with shared times passed\")\n",
    "\n",
    "#very complicated tests\n",
    "tdf7_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "             ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15]]\n",
    "tdf7 = pd.DataFrame(data=tdf7_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf8_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "             ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14]]\n",
    "tdf8 = pd.DataFrame(data=tdf8_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf9_data = [['AU', 3, 3, 2, 1], ['AU', 4, 4, 3, 2], ['AU', 5, 5, 4, 3],\n",
    "             ['NZ', 4, 14, 13, 12], ['NZ', 5, 15, 14, 13]]\n",
    "tdf9 = pd.DataFrame(data=tdf9_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "tdf10_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "              ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15],\n",
    "              ['FJ', 3, 23], ['FJ', 4, 24], ['FJ', 5, 25], ['FJ', 6, 26], ['FJ', 7, 27], ['FJ', 8, 28],\n",
    "              ['WS', 4, 34], ['WS', 5, 35]]\n",
    "tdf10 = pd.DataFrame(data=tdf10_data, columns=['citizen', 'TIME_PERIOD', 'new_val'])\n",
    "tdf11_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "              ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14],\n",
    "              ['FJ', 4, 24, 23], ['FJ', 5, 25, 24], ['FJ', 6, 26, 25], ['FJ', 7, 27, 26], ['FJ', 8, 28, 27],\n",
    "              ['WS', 5, 35, 34]]\n",
    "tdf11 = pd.DataFrame(data=tdf11_data, columns=['citizen', 'TIME_PERIOD', 'new_val', 'new_val - lag 1 quarter'])\n",
    "tdf12_data = [['AU', 5, 5, 4, 3, 2, 1],\n",
    "              ['FJ', 7, 27, 26, 25, 24, 23], ['FJ', 8, 28, 27, 26, 25, 24]]\n",
    "tdf12 = pd.DataFrame(data=tdf12_data, columns=['citizen', 'TIME_PERIOD', 'new_val', 'new_val - lag 1 quarter', 'new_val - lag 2 quarters', 'new_val - lag 3 quarters', 'new_val - lag 4 quarters'])\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf7, [\"val\"], ['citizen'], 1), \n",
    "                      tdf8), \"lag with 2 different start times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf7, [\"val\"], ['citizen'], 2), \n",
    "                      tdf9), \"lag with 2 different start times test failed, shift=2\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf10, [\"new_val\"], ['citizen'], 1), \n",
    "                      tdf11), \"lag with many different start times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf10, [\"new_val\"], ['citizen'], 4), \n",
    "                      tdf12), \"lag with many different start times test failed, shift=4\"\n",
    "print(\"\\t[+] tests with multiple start and end dates passed\")\n",
    "\n",
    "print(\"\\t[+] \\x1b[42mPASSED ALL\\x1b[0m lagging tests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000c9c4-3b3a-42e5-9216-8ed09a07d81d",
   "metadata": {},
   "source": [
    "## 2. Dataset Splitting & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858df89c-0bb2-4f9a-8ed8-74c294bdb6c4",
   "metadata": {},
   "source": [
    "### Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c25ccb96-637a-452b-83ed-a13d3f19b02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_VAR = \"TOTAL_POS\"\n",
    "\n",
    "y = df_lagged[TARGET_VAR]\n",
    "X = df_lagged.drop(['GENCONV', 'HUMSTAT', 'SUB_PROT', 'REJECTED', 'TOTAL_POS'], axis=1)\n",
    "#PLAN:\n",
    "#of 62 quarters...\n",
    "#QUARTERS_OF_LAG are lost bc they wont have the needed lagged features\n",
    "    \n",
    "new_quarters = [q for q in quarters if q >= quarters[QUARTERS_OF_LAG]]\n",
    "quarter_count = len(new_quarters) - 1\n",
    "\n",
    "TRAIN_PORTION = 0.6\n",
    "VAL_PORTION = 0.2\n",
    "TEST_PORTION = 0.2\n",
    "\n",
    "#take out last portion of quarters for testing\n",
    "#div_0 = new_quarters[0]\n",
    "#div_1 = new_quarters[int(quarter_count * train_split)]\n",
    "div_2 = new_quarters[int(quarter_count * (1 - TEST_PORTION))]\n",
    "div_3 = new_quarters[quarter_count]\n",
    "\n",
    "#seperate out test section\n",
    "X_test = X[(div_2 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_3)]\n",
    "y_test = y[(div_2 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978c04dd-2d3d-4902-9d37-6b458087502b",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "337b29b9-d03f-4b1d-8cdc-f7d407d56b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_ftrs = ['age', 'TIME_PERIOD']\n",
    "ordinal_cats = [['UNK','Y_LT14','Y14-17','Y18-34','Y35-64','Y_GE65'], quarters]\n",
    "                                                                     #^^i'm using quarters not new_quarters here so that\n",
    "                                                                     #  the model can still tell where in history this q is\n",
    "onehot_ftrs = ['citizen', 'geo', 'sex']\n",
    "#onehot_ftrs = ['geo', 'sex']\n",
    "minmax_ftrs = []\n",
    "std_ftrs = [a for a in X.columns.to_list() if 'TOTAL' in a]\n",
    "poly_ftrs = ['TOTAL_APPS', 'TOTAL_POS - lag 1 quarter', \"TOTAL_APPS - lag 1 quarter\"]\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(categories = ordinal_cats), ordinal_ftrs),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "preprocessor_poly = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(categories = ordinal_cats), ordinal_ftrs),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs),\n",
    "        ('poly', PolynomialFeatures(degree=(2,2), interaction_only=False), poly_ftrs)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13305695-6085-4e66-bcbb-8069de231eb9",
   "metadata": {},
   "source": [
    "## 3. General Model Development Functions\n",
    "### Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ab029e6-26ee-4e69-acab-0f560e4f8ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).sum() / len(y_pred))\n",
    "\n",
    "def ALL_ZERO_BASELINE(y_true):\n",
    "    return np.sqrt(((y_true) ** 2).sum() / len(y_true))\n",
    "\n",
    "def ALL_MEAN_BASELINE(y_train, y_true):\n",
    "    mean = y_train.mean()\n",
    "    return np.sqrt(((mean - y_true) ** 2).sum() / len(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3693a52-0934-48b3-8506-747c93d5d179",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dba19fa2-3ba5-49ba-9162-f57c5feff1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIMESTAMP_STR():\n",
    "    dt = datetime.datetime.now()\n",
    "    txt = \"{hour}:{minute:02.0f} on {day}-{month}-{year}\"\n",
    "    return txt.format(hour=dt.hour, minute=dt.minute, day=dt.day, month=dt.month, year=dt.year)\n",
    "\n",
    "def DF_ALL_PREDICTED(model):\n",
    "    df_new = df\n",
    "    df_new[\"TOTAL_APPS_PRED\"] = model.predict(X)\n",
    "\n",
    "UPDATE = True\n",
    "def Status_Update(t, message):\n",
    "    my_time = time.time()\n",
    "    if UPDATE:\n",
    "        print(str(message) + \" \\t-- in \" + str(time.time() - t) + \"s\")\n",
    "    return time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7920943e-ca4b-432e-a83d-2c8461eb67f1",
   "metadata": {},
   "source": [
    "### General Model-Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0deb9432-e6fc-43db-a61f-3b95545d62d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPipe_TimeSeries_RMSE(X, y, preprocessor, ML_algo, param_grid):\n",
    "    ALGO_NAME = str(ML_algo)[str(ML_algo).rindex('.')+1:-2]\n",
    "    MODEL_NAME = \"{algo}({time})\".format(algo=ALGO_NAME, time=TIMESTAMP_STR())\n",
    "    NUM_FOLDS = np.round(TRAIN_PORTION / VAL_PORTION).astype(int)\n",
    "    RANDOM_STATE = 14\n",
    "    print(\"[!] looking at model: \" + str(MODEL_NAME))\n",
    "    \n",
    "    print(\"\\t[*] doing initial dataset splitting\")\n",
    "    \n",
    "    #opt check 2\n",
    "    X_trains = []\n",
    "    y_trains = []\n",
    "    X_vals = []\n",
    "    y_vals = []\n",
    "    for i in range(1, NUM_FOLDS + 1):\n",
    "        train_portion = np.round(i * VAL_PORTION, 2)\n",
    "        div_0 = new_quarters[0]\n",
    "        div_1 = new_quarters[int(quarter_count * train_portion)]\n",
    "        div_2 = new_quarters[int(quarter_count * (train_portion + VAL_PORTION))]\n",
    "\n",
    "        X_trains.append(X[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "        y_trains.append(y[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "        X_vals.append(X[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "        y_vals.append(y[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "        print(\"\\t\\t[+] fold \" + str(i))\n",
    "    \n",
    "    param_scores = []\n",
    "    param_models = []\n",
    "    for p in param_grid:\n",
    "        T_PARAM_START = time.time()\n",
    "        fold_scores = []\n",
    "        print(\"\\t[*] looking at hyperparameters \" + str(p))\n",
    "        for i in range(NUM_FOLDS, NUM_FOLDS + 1):\n",
    "            T_FOLD_START = time.time()\n",
    "            #ADD OPTIMIZATION HERE:\n",
    "                #[2] NO NEED TO CONSTANTLY REDIVIDE THE DATA, SAME THREE FOLDS WILL BE USED EACH TIME REGARDLES OF HYPERPARAMAETERS\n",
    "                #[1] NO NEED TO CHECK FUTURE FOLDS IF EVEN A SCORE OF ZERO WOULDN'T BRING IT BELOW A BETTER FOUND PARAMETER ARRANGEMENT\n",
    "            train_portion = np.round(i * VAL_PORTION, 2)\n",
    "            \n",
    "            #opt check 1\n",
    "            if (i > 0 & len(param_scores) > 0):\n",
    "                best_param_score = param_scores[np.argmin(param_scores)]\n",
    "                if ((best_param_score * 3) < np.sum(fold_scores)):\n",
    "                    print(\"[!] best average score I could get with \" + str(np.sum(fold_scores)) + \" score already is worse than a previous params score of \" + str(best_param_score) + \", so giving up\")\n",
    "\n",
    "            mini_t = time.time()\n",
    "            \n",
    "            X_train = X_trains[i - 1]\n",
    "            y_train = y_trains[i - 1]\n",
    "            X_val = X_vals[i - 1]\n",
    "            y_val = y_vals[i - 1]\n",
    "            \n",
    "            #PORTION_OF_POINTS = 0.001\n",
    "            #X_train = X_train.sample(np.floor((len(X_train) * PORTION_OF_POINTS)).astype(int), random_state = RANDOM_STATE)\n",
    "            #y_train = y_train.loc[X_train.index]\n",
    "            #X_val = X_val.sample(np.floor((len(X_val) * PORTION_OF_POINTS)).astype(int), random_state = RANDOM_STATE)\n",
    "            #y_val = y_val.loc[X_val.index]\n",
    "            \n",
    "            mini_t = Status_Update(mini_t, \"split data\")\n",
    "\n",
    "            #make pipeline\n",
    "            if ((ALGO_NAME == \"SVR\") | (ALGO_NAME == \"LinearRegression\") | (ALGO_NAME == \"RandomForestRegressor\")):\n",
    "                algo = ML_algo(**p)\n",
    "            else:\n",
    "                algo = ML_algo(**p, random_state = RANDOM_STATE)\n",
    "            \n",
    "            #print(algo)\n",
    "            pipe = Pipeline(steps=[\n",
    "                        ('preprocess', preprocessor),\n",
    "                        ('model', algo)\n",
    "                    ], verbose=True)\n",
    "            \n",
    "            mini_t = Status_Update(mini_t, \"made pipeline\")\n",
    "\n",
    "            pipe.fit(X_train, y_train)\n",
    "            mini_t = Status_Update(mini_t, \"fit pipeline\")\n",
    "            \n",
    "            y_pred = pipe.predict(X_val)\n",
    "            score = RMSE(y_pred, y_val)\n",
    "            \n",
    "            fold_scores.append(score)\n",
    "            T_FOLD_END = time.time()\n",
    "            T_FOLD_ELAPSED = T_FOLD_END - T_FOLD_START\n",
    "            mini_t = Status_Update(mini_t, \"eval pipeline\")\n",
    "            print(\"\\t\\t[*] fold \" + str(i) + \" complete (test score of \" + str(score) + \") -- in \" + str(np.round(T_FOLD_ELAPSED, 3)) + \"s\")\n",
    "        score = np.mean(fold_scores)\n",
    "        param_scores.append(score)\n",
    "        param_models.append(pipe)\n",
    "        \n",
    "        T_PARAM_END = time.time()\n",
    "        T_PARAM_ELAPSED = T_PARAM_END - T_PARAM_START\n",
    "        print(\"\\t\\t[+] final score for params of \" + str(score) + \" -- in \" + str(np.round(T_PARAM_ELAPSED, 3)) + \"s\")\n",
    "        \n",
    "        if (np.argmin(param_scores) == (len(param_scores) - 1)):\n",
    "            best_model = param_models[np.argmin(param_scores)]\n",
    "            print(\"\\t\\t[!] new best param configuration, so saving model to path\")\n",
    "            path = \"../results/\" + MODEL_NAME + \".pkl\"\n",
    "            joblib.dump(best_model, path, compress = 1)\n",
    "            print(\"\\t\\t\\t[+] saved model to \" + str(path))\n",
    "        \n",
    "        \n",
    "    i_best = np.argmin(param_scores)\n",
    "    best_score = param_scores[i_best]\n",
    "    best_params = param_grid[i_best]\n",
    "    best_model = param_models[i_best]\n",
    "    print(\"\\t[+] best param configuration of \" + str(best_params) + \" found with score \" + str(best_score))\n",
    "    path = \"../results/\" + MODEL_NAME + \".pkl\"\n",
    "    joblib.dump(best_model, path, compress = 1)\n",
    "    print(\"\\t[+] saved model to \" + str(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ce1da7-5550-474d-91ba-7818b0d2c052",
   "metadata": {},
   "source": [
    "### General XGBoost Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6b02cfb-72b7-42a2-acf7-b0c85608594f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TRAIN_XGBOOST(X, y, preprocessor, ML_algo, param_grid):\n",
    "    ALGO_NAME = str(ML_algo)[str(ML_algo).rindex('.')+1:-2]\n",
    "    MODEL_NAME = \"{algo}({time})\".format(algo=ALGO_NAME, time=TIMESTAMP_STR())\n",
    "    NUM_FOLDS = np.round(TRAIN_PORTION / VAL_PORTION).astype(int)\n",
    "    RANDOM_STATE = 14\n",
    "    print(\"[!] looking at XGBoost model: \" + str(MODEL_NAME))\n",
    "    \n",
    "    print(\"\\t[*] doing initial dataset splitting\")\n",
    "    \n",
    "    #opt check 2\n",
    "    X_trains = []\n",
    "    y_trains = []\n",
    "    X_vals = []\n",
    "    y_vals = []\n",
    "    for i in range(1, NUM_FOLDS + 1):\n",
    "        train_portion = np.round(i * VAL_PORTION, 2)\n",
    "        div_0 = new_quarters[0]\n",
    "        div_1 = new_quarters[int(quarter_count * train_portion)]\n",
    "        div_2 = new_quarters[int(quarter_count * (train_portion + VAL_PORTION))]\n",
    "\n",
    "        X_trains.append(X[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "        y_trains.append(y[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "        X_vals.append(X[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "        y_vals.append(y[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "        print(\"\\t\\t[+] fold \" + str(i))\n",
    "    \n",
    "    param_scores = []\n",
    "    param_models = []\n",
    "    for p in param_grid:\n",
    "        T_PARAM_START = time.time()\n",
    "        fold_scores = []\n",
    "        print(\"\\t[*] looking at hyperparameters \" + str(p))\n",
    "        for i in range(1, NUM_FOLDS + 1):\n",
    "            T_FOLD_START = time.time()\n",
    "            #ADD OPTIMIZATION HERE:\n",
    "                #[2] NO NEED TO CONSTANTLY REDIVIDE THE DATA, SAME THREE FOLDS WILL BE USED EACH TIME REGARDLES OF HYPERPARAMAETERS\n",
    "                #[1] NO NEED TO CHECK FUTURE FOLDS IF EVEN A SCORE OF ZERO WOULDN'T BRING IT BELOW A BETTER FOUND PARAMETER ARRANGEMENT\n",
    "            train_portion = np.round(i * VAL_PORTION, 2)\n",
    "            \n",
    "            #opt check 1\n",
    "            if (i > 0 & len(param_scores) > 0):\n",
    "                best_param_score = param_scores[np.argmin(param_scores)]\n",
    "                if ((best_param_score * 3) < np.sum(fold_scores)):\n",
    "                    print(\"[!] best average score I could get with \" + str(np.sum(fold_scores)) + \" score already is worse than a previous params score of \" + str(best_param_score) + \", so giving up\")\n",
    "\n",
    "            mini_t = time.time()\n",
    "            \n",
    "            X_train = X_trains[i - 1]\n",
    "            y_train = y_trains[i - 1]\n",
    "            X_val = X_vals[i - 1]\n",
    "            y_val = y_vals[i - 1]\n",
    "            \n",
    "            PORTION_OF_POINTS = 0.01\n",
    "            X_train = X_train.sample(np.floor((len(X_train) * PORTION_OF_POINTS)).astype(int), random_state = RANDOM_STATE)\n",
    "            y_train = y_train.loc[X_train.index]\n",
    "            X_val = X_val.sample(np.floor((len(X_val) * PORTION_OF_POINTS)).astype(int), random_state = RANDOM_STATE)\n",
    "            y_val = y_val.loc[X_val.index]\n",
    "            \n",
    "            mini_t = Status_Update(mini_t, \"split data\")\n",
    "            \n",
    "            algo = ML_algo(**p, early_stopping_rounds=50)\n",
    "            \n",
    "            #print(algo)\n",
    "            mini_t = Status_Update(mini_t, \"made pipeline\")\n",
    "                \n",
    "            X_train = preprocessor.fit_transform(X_train)\n",
    "            X_val = preprocessor.transform(X_val)\n",
    "            \n",
    "            mini_t = Status_Update(mini_t, \"preprocess data\")\n",
    "\n",
    "            algo.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=0)\n",
    "            mini_t = Status_Update(mini_t, \"fit pipeline\")\n",
    "            \n",
    "            y_pred = algo.predict(X_val)\n",
    "            score = RMSE(y_pred, y_val)\n",
    "            \n",
    "            fold_scores.append(score)\n",
    "            T_FOLD_END = time.time()\n",
    "            T_FOLD_ELAPSED = T_FOLD_END - T_FOLD_START\n",
    "            mini_t = Status_Update(mini_t, \"eval pipeline\")\n",
    "            print(\"\\t\\t[*] fold \" + str(i) + \" complete (test score of \" + str(score) + \") -- in \" + str(np.round(T_FOLD_ELAPSED, 3)) + \"s\")\n",
    "        score = np.mean(fold_scores)\n",
    "        param_scores.append(score)\n",
    "        param_models.append(algo)\n",
    "        \n",
    "        T_PARAM_END = time.time()\n",
    "        T_PARAM_ELAPSED = T_PARAM_END - T_PARAM_START\n",
    "        print(\"\\t\\t[+] final score for params of \" + str(score) + \" -- in \" + str(np.round(T_PARAM_ELAPSED, 3)) + \"s\")\n",
    "        \n",
    "        path = \"../results/\" + MODEL_NAME + '[seed ' + str(p['seed']) + \"].pkl\"\n",
    "        joblib.dump(algo, path, compress = 1)\n",
    "        print(\"\\t\\t\\t[+] saved model to \" + str(path))\n",
    "        #if (np.argmin(param_scores) == (len(param_scores) - 1)):\n",
    "            #best_model = param_models[np.argmin(param_scores)]\n",
    "            #print(\"\\t\\t[!] new best param configuration, so saving model to path\")\n",
    "            #path = \"../results/\" + MODEL_NAME + \".pkl\"\n",
    "            #joblib.dump(best_model, path, compress = 1)\n",
    "            #print(\"\\t\\t\\t[+] saved model to \" + str(path))\n",
    "        \n",
    "        \n",
    "    i_best = np.argmin(param_scores)\n",
    "    best_score = param_scores[i_best]\n",
    "    best_params = param_grid[i_best]\n",
    "    best_model = param_models[i_best]\n",
    "    print(\"\\t[+] best param configuration of \" + str(best_params) + \" found with score \" + str(best_score))\n",
    "    path = \"../results/\" + MODEL_NAME + \".pkl\"\n",
    "    joblib.dump(best_model, path, compress = 1)\n",
    "    print(\"\\t[+] saved model to \" + str(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92427274-4cad-477d-a866-e084337bfcde",
   "metadata": {},
   "source": [
    "## 4. Model Training\n",
    "Based on the general model-training function, all models will be saved in .pkl format to `../results` in a file with the name `<Model Name>(<Timestamp>).pkl`\n",
    "### Import Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6123c660-65f9-421a-95dd-2360a7f5696f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression, ElasticNet\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac38aeaa-0409-486e-8f20-0f23a6e5feec",
   "metadata": {},
   "source": [
    "### Training Linear Models\n",
    "#### Linear Regression (L1, L2 and Elastic Net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99a93e3-68c9-40e0-a41a-3dc956c99762",
   "metadata": {},
   "outputs": [],
   "source": [
    "LASSO_PARAM_GRID = ParameterGrid({\n",
    "            'alpha': np.geomspace(0.01, 10000, 12), # no upper bound so the values are evenly spaced in log\n",
    "            })\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, Lasso, LASSO_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76066d07-2d8c-4c50-ada1-1d9ae6f04887",
   "metadata": {},
   "outputs": [],
   "source": [
    "RIDGE_PARAM_GRID = ParameterGrid({\n",
    "            'alpha': np.geomspace(0.01, 10000, 12), # no upper bound so the values are evenly spaced in log\n",
    "            })\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, Ridge, RIDGE_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf5dc42-bee5-45da-8c56-013dc9eb6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTIC_PARAM_GRID = {\n",
    "            'model__alpha': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000], # no upper bound so the values are evenly spaced in log\n",
    "            'model__l1_ratio': np.linspace(0.2, 1, 9)\n",
    "            }\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, ElasticNet, ELASTIC_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e840277-bd72-4e9a-a122-3b999b96bcd4",
   "metadata": {},
   "source": [
    "#### Linear Regression (with polynomial features introduced in preprocessing [here](#Preprocessing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabf5eaa-5869-4bdb-9f13-79dfa55959c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "RIDGE_PARAM_GRID_POLY = ParameterGrid({\n",
    "            'alpha': np.geomspace(0.01, 10000, 12), # no upper bound so the values are evenly spaced in log\n",
    "            })\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor_poly, Ridge, RIDGE_PARAM_GRID_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b15ed24-7b59-4bf6-ac5d-8ba641f0875b",
   "metadata": {},
   "source": [
    "### Training Non-Linear Models\n",
    "#### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9e08c0-0f59-4d58-a7cb-58b67234d3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "LINEARSVR_PARAM_GRID = ParameterGrid({\n",
    "    'C': [1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3, 1e4, 1e5], #tested just up to 1e2 initially but that was the best value, so expanded search\n",
    "    'dual': [\"auto\"]\n",
    "})\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, LinearSVR, LINEARSVR_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451eda35-6282-4dd9-a126-c8403163a363",
   "metadata": {},
   "source": [
    "#### XGBoost & RandomForestRegressor (using multiple random states to account for non-determinism)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9f21f2-6273-491d-ba63-54ce41f9847e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for random_state in range(0, 5):\n",
    "    print(\"WORKING ON random state = \" + str(random_state))\n",
    "    RF_PARAM_GRID = ParameterGrid({\n",
    "                'max_depth': [1, 3, 4, 7, 10, 14, 21, 31], # no upper bound so the values are evenly spaced in log\n",
    "                'max_features': np.linspace(0.2, 1, 5),\n",
    "                'random_state': [random_state]\n",
    "                })\n",
    "    \n",
    "    MLPipe_TimeSeries_RMSE(X, y, preprocessor, RandomForestRegressor, RF_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a5005b-deaf-4ccb-ac86-807638f1f3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for random_state in range(0, 5):\n",
    "    print(\"WORKING ON random state = \" + str(random_state))\n",
    "    XGB_PARAM_GRID = ParameterGrid({\n",
    "        \"learning_rate\": [0.03],\n",
    "        \"n_estimators\": [1000],\n",
    "        #\"early_stopping_rounds\": [50],\n",
    "        \"reg_alpha\": [1e0, 1e1, 1e-1, 0, 1e-2, 1e2],\n",
    "        \"reg_lambda\": [1e0, 1e1, 1e-1, 0, 1e-2, 1e2],\n",
    "        \"seed\": [1956, 14, 3],\n",
    "        #\"max_depth\": [1,3,10,30,100],\n",
    "        \"colsample_bytree\": [0.9],              \n",
    "        \"subsample\": [0.66]\n",
    "        })\n",
    "    TRAIN_XGBOOST(X, y, preprocessor, xgboost.XGBRegressor, XGB_PARAM_GRID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
