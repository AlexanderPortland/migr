{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10aa6b5c",
   "metadata": {},
   "source": [
    "# Splitting, Preprocessing and Model Development\n",
    "This notebook is used for:\n",
    "\n",
    "\n",
    "### Declaring Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "318f1efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import sklearn\n",
    "import time\n",
    "import warnings\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a4beb",
   "metadata": {},
   "source": [
    "### Color Palette & Typeface Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9835e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW = '#F2DC5D'\n",
    "GREEN = '#9BC53D'\n",
    "DARK_GREEN = '#597222'\n",
    "RED = '#C3423F'\n",
    "LIGHT_BLUE = '#2596BE'\n",
    "GRAY = '#666666'\n",
    "\n",
    "AXIS_SIZE = 12\n",
    "TITLE_SIZE = 16\n",
    "DESCRIPTION_SIZE = 9\n",
    "FIGURE_SIZE = (10*2/3,6*2/3)\n",
    "\n",
    "RANDOM_STATE = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849d3c5",
   "metadata": {},
   "source": [
    "### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f2f082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizen</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>GENCONV</th>\n",
       "      <th>HUMSTAT</th>\n",
       "      <th>SUB_PROT</th>\n",
       "      <th>REJECTED</th>\n",
       "      <th>TOTAL_POS</th>\n",
       "      <th>TOTAL_APPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221109</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221110</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221111</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221112</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221113</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7213806 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        citizen  sex     age geo TIME_PERIOD  GENCONV  HUMSTAT  SUB_PROT  \\\n",
       "0            AD    F     UNK  AT     2008-Q1        0        0         0   \n",
       "1            AD    F     UNK  AT     2008-Q2        0        0         0   \n",
       "2            AD    F     UNK  AT     2008-Q3        0        0         0   \n",
       "3            AD    F     UNK  AT     2008-Q4        0        0         0   \n",
       "4            AD    F     UNK  AT     2009-Q1        0        0         0   \n",
       "...         ...  ...     ...  ..         ...      ...      ...       ...   \n",
       "7221109      ZW  UNK  Y_LT14  UK     2019-Q3        0        0         0   \n",
       "7221110      ZW  UNK  Y_LT14  UK     2019-Q4        0        0         0   \n",
       "7221111      ZW  UNK  Y_LT14  UK     2020-Q1        0        0         0   \n",
       "7221112      ZW  UNK  Y_LT14  UK     2020-Q2        0        0         0   \n",
       "7221113      ZW  UNK  Y_LT14  UK     2020-Q3        0        0         0   \n",
       "\n",
       "         REJECTED  TOTAL_POS  TOTAL_APPS  \n",
       "0               0          0           0  \n",
       "1               0          0           0  \n",
       "2               0          0           0  \n",
       "3               0          0           0  \n",
       "4               0          0           0  \n",
       "...           ...        ...         ...  \n",
       "7221109         0          0           0  \n",
       "7221110         0          0           0  \n",
       "7221111         0          0           0  \n",
       "7221112         0          0           0  \n",
       "7221113         0          0           0  \n",
       "\n",
       "[7213806 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#****************************************************import dataset****************************************************\n",
    "df = pd.read_csv('../data/final.csv', dtype={'citizen': 'string', 'sex': 'string', 'age': 'string', 'decision': 'string', 'geo': 'string', 'TIME_PERIOD': 'string', 'GENCONV': \"Int64\", 'HUMSTAT': \"Int64\", 'SUB_PROT': \"Int64\", 'REJECTED': \"Int64\", 'TOTAL_POS': \"Int64\", 'TOTAL_APPS': \"Int64\", \"POS_RATE\": \"Float64\"}, keep_default_na=False, na_values=['nan'])\n",
    "\n",
    "##remove partial 2023-Q3 Data\n",
    "df = df[df[\"TIME_PERIOD\"] != \"2023-Q3\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500d090",
   "metadata": {},
   "source": [
    "## 1. Introduce Lagged Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8a5da77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizen</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>GENCONV</th>\n",
       "      <th>HUMSTAT</th>\n",
       "      <th>SUB_PROT</th>\n",
       "      <th>REJECTED</th>\n",
       "      <th>TOTAL_POS</th>\n",
       "      <th>TOTAL_APPS</th>\n",
       "      <th>TOTAL_POS - lag 1 quarter</th>\n",
       "      <th>TOTAL_POS - lag 2 quarters</th>\n",
       "      <th>TOTAL_POS - lag 3 quarters</th>\n",
       "      <th>TOTAL_POS - lag 4 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 1 quarter</th>\n",
       "      <th>TOTAL_APPS - lag 2 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 3 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 4 quarters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2010-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221109</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221110</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221111</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221112</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221113</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6731478 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        citizen  sex     age geo TIME_PERIOD  GENCONV  HUMSTAT  SUB_PROT  \\\n",
       "4            AD    F     UNK  AT     2009-Q1        0        0         0   \n",
       "5            AD    F     UNK  AT     2009-Q2        0        0         0   \n",
       "6            AD    F     UNK  AT     2009-Q3        0        0         0   \n",
       "7            AD    F     UNK  AT     2009-Q4        0        0         0   \n",
       "8            AD    F     UNK  AT     2010-Q1        0        0         0   \n",
       "...         ...  ...     ...  ..         ...      ...      ...       ...   \n",
       "7221109      ZW  UNK  Y_LT14  UK     2019-Q3        0        0         0   \n",
       "7221110      ZW  UNK  Y_LT14  UK     2019-Q4        0        0         0   \n",
       "7221111      ZW  UNK  Y_LT14  UK     2020-Q1        0        0         0   \n",
       "7221112      ZW  UNK  Y_LT14  UK     2020-Q2        0        0         0   \n",
       "7221113      ZW  UNK  Y_LT14  UK     2020-Q3        0        0         0   \n",
       "\n",
       "         REJECTED  TOTAL_POS  TOTAL_APPS  TOTAL_POS - lag 1 quarter  \\\n",
       "4               0          0           0                          0   \n",
       "5               0          0           0                          0   \n",
       "6               0          0           0                          0   \n",
       "7               0          0           0                          0   \n",
       "8               0          0           0                          0   \n",
       "...           ...        ...         ...                        ...   \n",
       "7221109         0          0           0                          0   \n",
       "7221110         0          0           0                          0   \n",
       "7221111         0          0           0                          0   \n",
       "7221112         0          0           0                          0   \n",
       "7221113         0          0           0                          0   \n",
       "\n",
       "         TOTAL_POS - lag 2 quarters  TOTAL_POS - lag 3 quarters  \\\n",
       "4                                 0                           0   \n",
       "5                                 0                           0   \n",
       "6                                 0                           0   \n",
       "7                                 0                           0   \n",
       "8                                 0                           0   \n",
       "...                             ...                         ...   \n",
       "7221109                           0                           0   \n",
       "7221110                           0                           0   \n",
       "7221111                           0                           0   \n",
       "7221112                           0                           0   \n",
       "7221113                           0                           0   \n",
       "\n",
       "         TOTAL_POS - lag 4 quarters  TOTAL_APPS - lag 1 quarter  \\\n",
       "4                                 0                           0   \n",
       "5                                 0                           0   \n",
       "6                                 0                           0   \n",
       "7                                 0                           0   \n",
       "8                                 0                           0   \n",
       "...                             ...                         ...   \n",
       "7221109                           0                           0   \n",
       "7221110                           0                           0   \n",
       "7221111                           0                           0   \n",
       "7221112                           0                           0   \n",
       "7221113                           0                           0   \n",
       "\n",
       "         TOTAL_APPS - lag 2 quarters  TOTAL_APPS - lag 3 quarters  \\\n",
       "4                                  0                            0   \n",
       "5                                  0                            0   \n",
       "6                                  0                            0   \n",
       "7                                  0                            0   \n",
       "8                                  0                            0   \n",
       "...                              ...                          ...   \n",
       "7221109                            0                            0   \n",
       "7221110                            0                            0   \n",
       "7221111                            0                            0   \n",
       "7221112                            0                            0   \n",
       "7221113                            0                            0   \n",
       "\n",
       "         TOTAL_APPS - lag 4 quarters  \n",
       "4                                  0  \n",
       "5                                  0  \n",
       "6                                  0  \n",
       "7                                  0  \n",
       "8                                  0  \n",
       "...                              ...  \n",
       "7221109                            0  \n",
       "7221110                            0  \n",
       "7221111                            0  \n",
       "7221112                            0  \n",
       "7221113                            0  \n",
       "\n",
       "[6731478 rows x 19 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#****************************************************re-sort dataframe****************************************************\n",
    "\n",
    "sort_order = ['citizen', 'sex', 'age', 'geo', 'TIME_PERIOD']\n",
    "df = df.sort_values(by =sort_order) \n",
    "\n",
    "#*********************************************create sequential list of quarters****************************************************\n",
    "\n",
    "quarters = []\n",
    "for i in range(2008, 2024):\n",
    "    quarters.append(str(i) + \"-Q1\")\n",
    "    quarters.append(str(i) + \"-Q2\")\n",
    "    quarters.append(str(i) + \"-Q3\")\n",
    "    quarters.append(str(i) + \"-Q4\")\n",
    "\n",
    "#****************************************************lagged features****************************************************\n",
    "\n",
    "QUARTERS_OF_LAG = (4 * 1)\n",
    "\n",
    "def add_lagged_features(df, features, maintained_columns, QUARTERS_OF_LAG):\n",
    "    quarters = np.unique(df[\"TIME_PERIOD\"])\n",
    "    def lagged_features(target_var, lag_count, unit):\n",
    "        lagged = pd.DataFrame()\n",
    "        columns = []\n",
    "        for i in range(1, lag_count + 1):\n",
    "            lagged = pd.concat([lagged, target_var.shift(i)], axis=1)\n",
    "            name = target_var.name\n",
    "            if (i == 1):\n",
    "                columns.append(name + \" - lag \" + str(i) + \" \" + str(unit))\n",
    "            else:\n",
    "                columns.append(name + \" - lag \" + str(i) + \" \" + str(unit) + \"s\")\n",
    "        lagged.columns = columns\n",
    "        return lagged.astype('Int64')\n",
    "\n",
    "    #introduce lag for each feature\n",
    "    df_lagged = df\n",
    "    for f in features:\n",
    "        df_lagged = pd.concat([df_lagged, lagged_features(df[f], QUARTERS_OF_LAG, \"quarter\")], axis=1)\n",
    "\n",
    "    #remove all features with less than the lag amount of historical data\n",
    "    #df_lagged = df_lagged[df_lagged.eq()]\n",
    "    for i in range(0, QUARTERS_OF_LAG):\n",
    "        shift_eq = df_lagged.eq(df_lagged.shift())\n",
    "        keep = shift_eq[maintained_columns[0]]\n",
    "        for j in range(1, len(maintained_columns)):\n",
    "            keep = keep & shift_eq[maintained_columns[j]]\n",
    "        df_lagged = df_lagged[keep]\n",
    "        #print(\"lagged i\" + str(i) + \" of \" + str(QUARTERS_OF_LAG))\n",
    "    \n",
    "    return df_lagged\n",
    "\n",
    "df_lagged = add_lagged_features(df, [\"TOTAL_POS\", \"TOTAL_APPS\"], ['citizen', 'age', 'sex', 'geo'], QUARTERS_OF_LAG)\n",
    "\n",
    "df_lagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e5062",
   "metadata": {},
   "source": [
    "### Lagged Feature Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cfc60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] testing lagging function\n",
      "\t[+] basic lag tests passed\n",
      "\t[+] tests with shared times passed\n",
      "\t[+] tests with multiple start and end dates passed\n",
      "\t[+] \u001b[42mPASSED ALL\u001b[0m lagging tests\n"
     ]
    }
   ],
   "source": [
    "#***********************************************testing equivalence function****************************************************\n",
    "def equivalent_dfs(df1, df2):\n",
    "    return (df1.reset_index(drop=True) == df2.reset_index(drop=True)).all().all()\n",
    "\n",
    "#****************************************************lagging testing****************************************************\n",
    "print(\"[*] testing lagging function\")\n",
    "#simple tests\n",
    "tdf0_data = [['AR', 1, 1], ['AR', 2, 2], ['AR', 3, 3], ['AR', 4, 4], ['AR', 5, 5]]\n",
    "tdf0 = pd.DataFrame(data=tdf0_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf1_data = [['AR', 2, 2, 1], ['AR', 3, 3, 2], ['AR', 4, 4, 3], ['AR', 5, 5, 4]]\n",
    "tdf1 = pd.DataFrame(data=tdf1_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf2_data = [['AR', 3, 3, 2, 1], ['AR', 4, 4, 3, 2], ['AR', 5, 5, 4, 3]]\n",
    "tdf2 = pd.DataFrame(data=tdf2_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "tdf3_data = [['AR', 4, 4, 3, 2, 1], ['AR', 5, 5, 4, 3, 2]]\n",
    "tdf3 = pd.DataFrame(data=tdf3_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters', 'val - lag 3 quarters'])\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 1), \n",
    "                      tdf1), \"basic lag test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 2), \n",
    "                      tdf2), \"basic lag test failed, shift=2\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 3), \n",
    "                      tdf3), \"basic lag test failed, shift=3\"\n",
    "print(\"\\t[+] basic lag tests passed\")\n",
    "\n",
    "#more advanced tests\n",
    "tdf4_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "             ['NZ', 1, 11], ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15]]\n",
    "tdf4 = pd.DataFrame(data=tdf4_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf5_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "             ['NZ', 2, 12, 11], ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14]]\n",
    "tdf5 = pd.DataFrame(data=tdf5_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf6_data = [['AU', 3, 3, 2, 1], ['AU', 4, 4, 3, 2], ['AU', 5, 5, 4, 3],\n",
    "             ['NZ', 3, 13, 12, 11], ['NZ', 4, 14, 13, 12], ['NZ', 5, 15, 14, 13]]\n",
    "tdf6 = pd.DataFrame(data=tdf6_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf4, [\"val\"], ['citizen'], 1), \n",
    "                      tdf5), \"lag with shared times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf4, [\"val\"], ['citizen'], 2), \n",
    "                      tdf6), \"lag with shared times test failed, shift=2\"\n",
    "print(\"\\t[+] tests with shared times passed\")\n",
    "\n",
    "#very complicated tests\n",
    "tdf7_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "             ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15]]\n",
    "tdf7 = pd.DataFrame(data=tdf7_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf8_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "             ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14]]\n",
    "tdf8 = pd.DataFrame(data=tdf8_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf9_data = [['AU', 3, 3, 2, 1], ['AU', 4, 4, 3, 2], ['AU', 5, 5, 4, 3],\n",
    "             ['NZ', 4, 14, 13, 12], ['NZ', 5, 15, 14, 13]]\n",
    "tdf9 = pd.DataFrame(data=tdf9_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "tdf10_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "              ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15],\n",
    "              ['FJ', 3, 23], ['FJ', 4, 24], ['FJ', 5, 25], ['FJ', 6, 26], ['FJ', 7, 27], ['FJ', 8, 28],\n",
    "              ['WS', 4, 34], ['WS', 5, 35]]\n",
    "tdf10 = pd.DataFrame(data=tdf10_data, columns=['citizen', 'TIME_PERIOD', 'new_val'])\n",
    "tdf11_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "              ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14],\n",
    "              ['FJ', 4, 24, 23], ['FJ', 5, 25, 24], ['FJ', 6, 26, 25], ['FJ', 7, 27, 26], ['FJ', 8, 28, 27],\n",
    "              ['WS', 5, 35, 34]]\n",
    "tdf11 = pd.DataFrame(data=tdf11_data, columns=['citizen', 'TIME_PERIOD', 'new_val', 'new_val - lag 1 quarter'])\n",
    "tdf12_data = [['AU', 5, 5, 4, 3, 2, 1],\n",
    "              ['FJ', 7, 27, 26, 25, 24, 23], ['FJ', 8, 28, 27, 26, 25, 24]]\n",
    "tdf12 = pd.DataFrame(data=tdf12_data, columns=['citizen', 'TIME_PERIOD', 'new_val', 'new_val - lag 1 quarter', 'new_val - lag 2 quarters', 'new_val - lag 3 quarters', 'new_val - lag 4 quarters'])\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf7, [\"val\"], ['citizen'], 1), \n",
    "                      tdf8), \"lag with 2 different start times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf7, [\"val\"], ['citizen'], 2), \n",
    "                      tdf9), \"lag with 2 different start times test failed, shift=2\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf10, [\"new_val\"], ['citizen'], 1), \n",
    "                      tdf11), \"lag with many different start times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf10, [\"new_val\"], ['citizen'], 4), \n",
    "                      tdf12), \"lag with many different start times test failed, shift=4\"\n",
    "print(\"\\t[+] tests with multiple start and end dates passed\")\n",
    "\n",
    "print(\"\\t[+] \\x1b[42mPASSED ALL\\x1b[0m lagging tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd114121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d6700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb22ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1acfa54",
   "metadata": {},
   "source": [
    "## 2. Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8ace99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************splitting****************************************************\n",
    "TARGET_VAR = \"TOTAL_POS\"\n",
    "\n",
    "y = df_lagged[TARGET_VAR]\n",
    "X = df_lagged.drop(['GENCONV', 'HUMSTAT', 'SUB_PROT', 'REJECTED', 'TOTAL_POS'], axis=1)\n",
    "#PLAN:\n",
    "#of 62 quarters...\n",
    "#QUARTERS_OF_LAG are lost bc they wont have the needed lagged features\n",
    "    \n",
    "new_quarters = [q for q in quarters if q >= quarters[QUARTERS_OF_LAG]]\n",
    "quarter_count = len(new_quarters) - 1\n",
    "\n",
    "TRAIN_PORTION = 0.6\n",
    "VAL_PORTION = 0.2\n",
    "TEST_PORTION = 0.2\n",
    "\n",
    "#take out last portion of quarters for testing\n",
    "#div_0 = new_quarters[0]\n",
    "#div_1 = new_quarters[int(quarter_count * train_split)]\n",
    "div_2 = new_quarters[int(quarter_count * (1 - TEST_PORTION))]\n",
    "div_3 = new_quarters[quarter_count]\n",
    "\n",
    "#seperate out test section\n",
    "X_test = X[(div_2 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_3)]\n",
    "y_test = y[(div_2 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f0cdbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).sum() / len(y_pred))\n",
    "\n",
    "def BASELINE_RMSE(y_true):\n",
    "    return ALL_ZERO_BASELINE(y_true)\n",
    "\n",
    "def ALL_ZERO_BASELINE(y_true):\n",
    "    return np.sqrt(((y_true) ** 2).sum() / len(y_true))\n",
    "\n",
    "def ALL_ONE_BASELINE(y_true):\n",
    "    return np.sqrt(((1 - y_true) ** 2).sum() / len(y_true))\n",
    "\n",
    "def ALL_MEAN_BASELINE(y_train, y_true):\n",
    "    mean = y_train.mean()\n",
    "    return np.sqrt(((mean - y_true) ** 2).sum() / len(y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "21426ce1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (3885168377.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[96], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    if ((best_param_score * 3) < np.sum(fold\u001b[0m\n\u001b[0m                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "def MLPipe_TimeSeries_RMSE(X, y, preprocessor, ML_algo, param_grid):\n",
    "    print(\"[!] looking at model \" + str(ML_algo))\n",
    "    param_scores = []\n",
    "    for p in param_grid:\n",
    "        T_PARAM_START = time.time()\n",
    "        fold_scores = []\n",
    "        print(\"\\t[*] looking at hyperparameters \" + str(p))\n",
    "        for i in range(1, np.round(TRAIN_PORTION / VAL_PORTION).astype(int) + 1):\n",
    "            T_FOLD_START = time.time()\n",
    "            #ADD OPTIMIZATION HERE:\n",
    "                #[] 1. NO NEED TO CONSTANTLY REDIVIDE THE DATA, SAME THREE FOLDS WILL BE USED EACH TIME REGARDLES OF HYPERPARAMAETERS\n",
    "                #[] NO NEED TO CHECK FUTURE FOLDS IF EVEN A SCORE OF ZERO WOULDN'T BRING IT BELOW A BETTER FOUND PARAMETER ARRANGEMENT\n",
    "            train_portion = np.round(i * VAL_PORTION, 2)\n",
    "            \n",
    "            #opt check 1\n",
    "            if (i > 0 & len(param_scores) > 0):\n",
    "                best_param_score = param_scores[np.argmin(param_scores)]\n",
    "                if ((best_param_score * 3) < np.sum(fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d78ba520",
   "metadata": {},
   "outputs": [],
   "source": [
    "UPDATE = False\n",
    "def Status_Update(t, message):\n",
    "    my_time = time.time()\n",
    "    if UPDATE:\n",
    "        print(str(message) + \" \\t-- in \" + str(time.time() - t) + \"s\")\n",
    "    return time.time()\n",
    "\n",
    "def MLPipe_TimeSeries_RMSE(X, y, preprocessor, ML_algo, param_grid):\n",
    "    NUM_FOLDS = np.round(TRAIN_PORTION / VAL_PORTION).astype(int)\n",
    "    X_trains = []\n",
    "    y_trains = []\n",
    "    X_vals = []\n",
    "    y_vals = []\n",
    "    for i in range(1, NUM_FOLDS + 1):\n",
    "        train_portion = np.round(i * VAL_PORTION, 2)\n",
    "        div_0 = new_quarters[0]\n",
    "        div_1 = new_quarters[int(quarter_count * train_portion)]\n",
    "        div_2 = new_quarters[int(quarter_count * (train_portion + VAL_PORTION))]\n",
    "\n",
    "        X_trains.append(X[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "        y_trains.append(y[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "        X_vals.append(X[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "        y_vals.append(y[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "    \n",
    "    \n",
    "    RANDOM_STATE = 14\n",
    "    print(\"[!] looking at model \" + str(ML_algo))\n",
    "    param_scores = []\n",
    "    for p in param_grid:\n",
    "        T_PARAM_START = time.time()\n",
    "        fold_scores = []\n",
    "        print(\"\\t[*] looking at hyperparameters \" + str(p))\n",
    "        for i in range(1, NUM_FOLDS + 1):\n",
    "            T_FOLD_START = time.time()\n",
    "            #ADD OPTIMIZATION HERE:\n",
    "                #[] NO NEED TO CONSTANTLY REDIVIDE THE DATA, SAME THREE FOLDS WILL BE USED EACH TIME REGARDLES OF HYPERPARAMAETERS\n",
    "                #[1] NO NEED TO CHECK FUTURE FOLDS IF EVEN A SCORE OF ZERO WOULDN'T BRING IT BELOW A BETTER FOUND PARAMETER ARRANGEMENT\n",
    "            train_portion = np.round(i * VAL_PORTION, 2)\n",
    "            \n",
    "            #opt check 1\n",
    "            if (i > 0 & len(param_scores) > 0):\n",
    "                best_param_score = param_scores[np.argmin(param_scores)]\n",
    "                if ((best_param_score * 3) < np.sum(fold_scores)):\n",
    "                    print(\"[!] best average score I could get with \" + str(np.sum(fold_scores)) + \" score already is worse than a previous params score of \" + str(best_param_score) + \", so giving up\")\n",
    "\n",
    "            mini_t = time.time()\n",
    "            \n",
    "            #div_0 = new_quarters[0]\n",
    "            #div_1 = new_quarters[int(quarter_count * train_portion)]\n",
    "            #div_2 = new_quarters[int(quarter_count * (train_portion + VAL_PORTION))]\n",
    "\n",
    "            X_train = X_trains[i - 1]\n",
    "            y_train = y_trains[i - 1]\n",
    "            X_val = X_vals[i - 1]\n",
    "            y_val = y_vals[i - 1]\n",
    "            \n",
    "            PORTION_OF_POINTS = 0.001\n",
    "            X_train = X_train.sample(np.floor((len(X_train) * PORTION_OF_POINTS)).astype(int), random_state = RANDOM_STATE)\n",
    "            y_train = y_train.loc[X_train.index]\n",
    "            \n",
    "            X_val = X_val.sample(np.floor((len(X_val) * PORTION_OF_POINTS)).astype(int), random_state = RANDOM_STATE)\n",
    "            y_val = y_val.loc[X_val.index]\n",
    "            \n",
    "            mini_t = Status_Update(mini_t, \"split data\")\n",
    "\n",
    "            #make pipeline\n",
    "            algo = ML_algo(**p, random_state = RANDOM_STATE)\n",
    "            #print(algo)\n",
    "            pipe = Pipeline(steps=[\n",
    "                        ('preprocess', preprocessor),\n",
    "                        ('model', algo)\n",
    "                    ])\n",
    "            \n",
    "            mini_t = Status_Update(mini_t, \"made pipeline\")\n",
    "\n",
    "            pipe.fit(X_train, y_train)\n",
    "            mini_t = Status_Update(mini_t, \"fit pipeline\")\n",
    "            \n",
    "            y_pred = pipe.predict(X_val)\n",
    "            score = RMSE(y_pred, y_val)\n",
    "            #zero_baseline = ALL_ZERO_BASELINE(y_val)\n",
    "            #one_baseline = ALL_ONE_BASELINE(y_val)\n",
    "            #mean_baseline = ALL_MEAN_BASELINE(y_train, y_val)\n",
    "            fold_scores.append(score)\n",
    "            T_FOLD_END = time.time()\n",
    "            T_FOLD_ELAPSED = T_FOLD_END - T_FOLD_START\n",
    "            mini_t = Status_Update(mini_t, \"eval pipeline\")\n",
    "            #print(\"\\t\\t[*] fold \" + str(i) + \" complete (test score of \" + str(score) + \") -- in \" + str(np.round(T_FOLD_ELAPSED, 3)) + \"s\")\n",
    "        score = np.mean(fold_scores)\n",
    "        param_scores.append(score)\n",
    "        T_PARAM_END = time.time()\n",
    "        T_PARAM_ELAPSED = T_PARAM_END - T_PARAM_START\n",
    "        print(\"\\t\\t[+] final score for params of \" + str(score) + \" -- in \" + str(np.round(T_PARAM_ELAPSED, 3)) + \"s\")\n",
    "\n",
    "    i_best = np.argmin(param_scores)\n",
    "    best_score = param_scores[i_best]\n",
    "    best_params = param_grid[i_best]\n",
    "    print(\"\\t[+] best param configuration of \" + str(best_params) + \" found with score \" + str(best_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "f7116a11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] looking at model <class 'sklearn.ensemble._forest.RandomForestRegressor'>\n",
      "\t[*] looking at hyperparameters {'max_depth': 1, 'max_features': 0.2}\n",
      "\t\t[+] final score for params of 7.590928734722738 -- in 1.501s\n",
      "\t[*] looking at hyperparameters {'max_depth': 1, 'max_features': 0.6000000000000001}\n",
      "\t\t[+] final score for params of 7.609499004521717 -- in 0.42s\n",
      "\t[*] looking at hyperparameters {'max_depth': 1, 'max_features': 1.0}\n",
      "\t\t[+] final score for params of 7.650182079730723 -- in 0.502s\n",
      "\t[*] looking at hyperparameters {'max_depth': 3, 'max_features': 0.2}\n",
      "\t\t[+] final score for params of 7.619513362306108 -- in 0.409s\n",
      "\t[*] looking at hyperparameters {'max_depth': 3, 'max_features': 0.6000000000000001}\n",
      "\t\t[+] final score for params of 7.857307474837122 -- in 0.693s\n",
      "\t[*] looking at hyperparameters {'max_depth': 3, 'max_features': 1.0}\n",
      "\t\t[+] final score for params of 8.099697882255365 -- in 0.969s\n",
      "\t[*] looking at hyperparameters {'max_depth': 7, 'max_features': 0.2}\n",
      "\t\t[+] final score for params of 7.740503021039468 -- in 0.573s\n",
      "\t[*] looking at hyperparameters {'max_depth': 7, 'max_features': 0.6000000000000001}\n",
      "\t\t[+] final score for params of 7.944102885775618 -- in 1.176s\n",
      "\t[*] looking at hyperparameters {'max_depth': 7, 'max_features': 1.0}\n",
      "\t\t[+] final score for params of 8.045773541129561 -- in 1.782s\n",
      "\t[*] looking at hyperparameters {'max_depth': 14, 'max_features': 0.2}\n",
      "\t\t[+] final score for params of 7.7053324131872225 -- in 0.716s\n",
      "\t[*] looking at hyperparameters {'max_depth': 14, 'max_features': 0.6000000000000001}\n",
      "\t\t[+] final score for params of 7.867326301616963 -- in 1.752s\n",
      "\t[*] looking at hyperparameters {'max_depth': 14, 'max_features': 1.0}\n",
      "\t\t[+] final score for params of 8.180456372701514 -- in 2.826s\n",
      "\t[*] looking at hyperparameters {'max_depth': 31, 'max_features': 0.2}\n",
      "\t\t[+] final score for params of 7.776627133053368 -- in 0.727s\n",
      "\t[*] looking at hyperparameters {'max_depth': 31, 'max_features': 0.6000000000000001}\n",
      "\t\t[+] final score for params of 8.018986567614187 -- in 1.784s\n",
      "\t[*] looking at hyperparameters {'max_depth': 31, 'max_features': 1.0}\n",
      "\t\t[+] final score for params of 8.090725827000712 -- in 2.899s\n",
      "\t[+] best param configuration of {'max_features': 0.2, 'max_depth': 1} found with score 7.590928734722738\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "RIDGE_PARAM_GRID = ParameterGrid({\n",
    "            'alpha': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100], # no upper bound so the values are evenly spaced in log\n",
    "            })\n",
    "RIDGE_PARAM_GRID_SMALL = ParameterGrid({\n",
    "            'alpha': [0.1, 1, 10, 100], # no upper bound so the values are evenly spaced in log\n",
    "            })\n",
    "\n",
    "RF_PARAM_GRID = ParameterGrid({\n",
    "            'max_depth': [3, 4, 7, 10, 14, 21, 31], # no upper bound so the values are evenly spaced in log\n",
    "            'max_features': np.linspace(0.2, 1, 5)\n",
    "            })\n",
    "RF_PARAM_GRID_SMALL = ParameterGrid({\n",
    "            'max_depth': [1, 3, 7, 14, 31], # no upper bound so the values are evenly spaced in log\n",
    "            'max_features': np.linspace(0.2, 1, 3)\n",
    "            })\n",
    "\n",
    "#MLPipe_TimeSeries_RMSE(X.drop(\"citizen\", axis=1), y, preprocessor, Ridge, RIDGE_PARAM_GRID_SMALL)\n",
    "#MLPipe_TimeSeries_RMSE(X, y, preprocessor, Ridge, RIDGE_PARAM_GRID_SMALL)\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, RandomForestRegressor, RF_PARAM_GRID_SMALL)\n",
    "#is taking about 70s for first fold\n",
    "#fold time is about 6 times first fold time assuming linearity?? so 6ish minutes per hyperparameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c90332",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "83894755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34.10471956418444, 34.104719678078204, 34.10472081334507, 34.10473389081692]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "07c7a178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "856393     0\n",
       "3615493    0\n",
       "3461708    0\n",
       "5190754    0\n",
       "6994996    0\n",
       "          ..\n",
       "3845663    0\n",
       "4154197    0\n",
       "6048304    0\n",
       "4377339    0\n",
       "6717900    0\n",
       "Name: TOTAL_POS, Length: 385862, dtype: Int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_partial = X_test.sample(np.floor((len(X_test) * 0.3)).astype(int))\n",
    "y_test_partial = y_test.loc[X_test_partial.index]\n",
    "y_test_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6d7f8874",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trains = []\n",
    "y_trains = []\n",
    "X_vals = []\n",
    "y_vals = []\n",
    "for i in range(1, 3 + 1):\n",
    "    train_portion = np.round(i * VAL_PORTION, 2)\n",
    "    div_0 = new_quarters[0]\n",
    "    div_1 = new_quarters[int(quarter_count * train_portion)]\n",
    "    div_2 = new_quarters[int(quarter_count * (train_portion + VAL_PORTION))]\n",
    "\n",
    "    X_trains.append(X[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "    y_trains.append(y[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "    X_vals.append(X[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "    y_vals.append(y[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "146a376f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[178], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_trains[\u001b[38;5;241m3\u001b[39m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "X_trains[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1c2ba7b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.01}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_best = np.argmin(param_scores)\n",
    "param_scores[i_best]\n",
    "param_grid[i_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1843b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c798a472",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b4f467",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac5f9f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e88d976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8420b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old split checking\n",
    "def check_split_sizes(X, train, test, val):\n",
    "    fails = 0\n",
    "    print(\"[*] checking train test val split\")\n",
    "    train_set_qs = set(train[\"TIME_PERIOD\"])\n",
    "    test_set_qs = set(test[\"TIME_PERIOD\"])\n",
    "    val_set_qs = set(val[\"TIME_PERIOD\"])\n",
    "    \n",
    "    #check for TIME_PERIOD overlap\n",
    "    shared = (train_set_qs & test_set_qs) | (val_set_qs & test_set_qs) | (train_set_qs & val_set_qs)\n",
    "    if (len(shared) != 0):\n",
    "        warnings.warn('\\t[-] overlap between train, test, or val time_periods')\n",
    "        fails+=1\n",
    "    else:\n",
    "        print(\"\\t[+] no overlap between train, test, or val TIME_PERIODS\")\n",
    "        \n",
    "    #check for a fairly even 60/20/20 split\n",
    "    NAMES = ['train', 'test ', 'val  ']\n",
    "    TARGETS = [0.6, 0.2, 0.2]\n",
    "    ALLOWED_FRACTION_ERROR = 0.02\n",
    "    sizes = [len(train) / len(X), len(test) / len(X), len(val) / len(X)]\n",
    "    for i in range(0, 3):\n",
    "        if (np.abs(sizes[i] - TARGETS[i]) < ALLOWED_FRACTION_ERROR):\n",
    "            print(\"\\t[+] \" + str(NAMES[i]) + \" is \" + str(np.round(sizes[i], 3)) + \" of datapoints which is within bounds of its \" + str(TARGETS[i]) + \" target\")\n",
    "        else:\n",
    "            warnings.warn(\"\\t[-] \" + str(NAMES[i]) + \" is \" + str(np.round(sizes[i], 3)) + \" of datapoints which is out of bounds\")\n",
    "            fails+=1\n",
    "\n",
    "    if (fails == 0):\n",
    "        print(\"\\t[+] \\x1b[42mPASSED ALL\\x1b[0m train test val split tests\")\n",
    "    else:\n",
    "        print(\"\\t[?] \\033[91mFAILED \" + str(fails) + \"\\033[0m train test val split tests\")\n",
    "        \n",
    "\n",
    "#check_split_sizes(X, X_train, X_test, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d982fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0f57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b72b064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdadb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063c616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30ce7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25946758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b8071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d532059",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "650c131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3783348, 22)\n",
      "(3783348, 240)\n",
      "[[ 0.  8.  1. ...  1.  0.  0.]\n",
      " [ 0.  9.  1. ...  1.  0.  0.]\n",
      " [ 0. 10.  1. ...  1.  0.  0.]\n",
      " ...\n",
      " [ 1. 38.  0. ...  0.  0.  1.]\n",
      " [ 1. 39.  0. ...  0.  0.  1.]\n",
      " [ 1. 40.  0. ...  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#****************************************************feature scaling********************************************************\n",
    "\n",
    "ordinal_ftrs = ['age', 'TIME_PERIOD']\n",
    "ordinal_cats = [['UNK','Y_LT14','Y14-17','Y18-34','Y35-64','Y_GE65'], quarters]\n",
    "                                                                     #^^i'm using quarters not new_quarters here so that\n",
    "                                                                     #  the model can still tell where in history this q is\n",
    "onehot_ftrs = ['citizen', 'geo', 'sex']\n",
    "#onehot_ftrs = ['geo', 'sex']\n",
    "minmax_ftrs = []\n",
    "std_ftrs = []\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(categories = ordinal_cats), ordinal_ftrs),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)]) # for now we only preprocess \n",
    "                                                       # later on we will add other steps here\n",
    "\n",
    "X_train_prep = clf.fit_transform(X_train)\n",
    "X_val_prep = clf.transform(X_val)\n",
    "X_test_prep = clf.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train_prep.shape)\n",
    "print(X_train_prep)\n",
    "#X_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55328c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_param_grid = {\n",
    "            'model__alpha': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100], # no upper bound so the values are evenly spaced in log\n",
    "            } \n",
    "\n",
    "ridge_test_scores, ridge_best_models = MLpipe_RMSE(preprocessor, Ridge, ridge_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************training models****************************************************\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# function for the ML pipeline as outlined above \n",
    "def MLpipe_RMSE(preprocessor, ML_algo, param_grid):\n",
    "    '''\n",
    "    !This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    !The RMSE is minimized in cross-validation.\n",
    "\n",
    "    !You should:\n",
    "\n",
    "    !1. Loop through 10 different random states\n",
    "    !2. Split your data \n",
    "    !3. Fit a model using GridSearchCV with KFold and the predefined Preprocessor \n",
    "    !4. Calculate the model's error on the test set \n",
    "    !5. Return a list of 10 test scores and 10 best models \n",
    "    '''\n",
    "    \n",
    "    # lists to be returned \n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    \n",
    "    # your code here...\n",
    "    for RANDOM_STATE in range(0, 10):\n",
    "        pipe = Pipeline(steps=[\n",
    "                ('preprocess', preprocessor),\n",
    "                ('model', ML_algo())\n",
    "            ])\n",
    "\n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid,scoring = 'neg_root_mean_squared_error', \\\n",
    "                            return_train_score = True, n_jobs=-2, verbose=True)\n",
    "\n",
    "        grid.fit(X_val, y_val)\n",
    "        \n",
    "        results = pd.DataFrame(grid.cv_results_)\n",
    "        \n",
    "        best_models.append(grid)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        test_scores.append(np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab34edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
