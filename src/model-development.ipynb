{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10aa6b5c",
   "metadata": {},
   "source": [
    "# Splitting, Preprocessing and Model Development\n",
    "This notebook is used for:\n",
    "\n",
    "\n",
    "### Declaring Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318f1efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import sklearn\n",
    "import warnings\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a4beb",
   "metadata": {},
   "source": [
    "### Color Palette & Typeface Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9835e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW = '#F2DC5D'\n",
    "GREEN = '#9BC53D'\n",
    "DARK_GREEN = '#597222'\n",
    "RED = '#C3423F'\n",
    "LIGHT_BLUE = '#2596BE'\n",
    "GRAY = '#666666'\n",
    "\n",
    "AXIS_SIZE = 12\n",
    "TITLE_SIZE = 16\n",
    "DESCRIPTION_SIZE = 9\n",
    "FIGURE_SIZE = (10*2/3,6*2/3)\n",
    "\n",
    "RANDOM_STATE = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849d3c5",
   "metadata": {},
   "source": [
    "### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f2f082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizen</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>GENCONV</th>\n",
       "      <th>HUMSTAT</th>\n",
       "      <th>SUB_PROT</th>\n",
       "      <th>REJECTED</th>\n",
       "      <th>TOTAL_POS</th>\n",
       "      <th>TOTAL_APPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221109</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221110</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221111</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221112</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221113</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7213806 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        citizen  sex     age geo TIME_PERIOD  GENCONV  HUMSTAT  SUB_PROT  \\\n",
       "0            AD    F     UNK  AT     2008-Q1        0        0         0   \n",
       "1            AD    F     UNK  AT     2008-Q2        0        0         0   \n",
       "2            AD    F     UNK  AT     2008-Q3        0        0         0   \n",
       "3            AD    F     UNK  AT     2008-Q4        0        0         0   \n",
       "4            AD    F     UNK  AT     2009-Q1        0        0         0   \n",
       "...         ...  ...     ...  ..         ...      ...      ...       ...   \n",
       "7221109      ZW  UNK  Y_LT14  UK     2019-Q3        0        0         0   \n",
       "7221110      ZW  UNK  Y_LT14  UK     2019-Q4        0        0         0   \n",
       "7221111      ZW  UNK  Y_LT14  UK     2020-Q1        0        0         0   \n",
       "7221112      ZW  UNK  Y_LT14  UK     2020-Q2        0        0         0   \n",
       "7221113      ZW  UNK  Y_LT14  UK     2020-Q3        0        0         0   \n",
       "\n",
       "         REJECTED  TOTAL_POS  TOTAL_APPS  \n",
       "0               0          0           0  \n",
       "1               0          0           0  \n",
       "2               0          0           0  \n",
       "3               0          0           0  \n",
       "4               0          0           0  \n",
       "...           ...        ...         ...  \n",
       "7221109         0          0           0  \n",
       "7221110         0          0           0  \n",
       "7221111         0          0           0  \n",
       "7221112         0          0           0  \n",
       "7221113         0          0           0  \n",
       "\n",
       "[7213806 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#****************************************************import dataset****************************************************\n",
    "df = pd.read_csv('../data/final.csv', dtype={'citizen': 'string', 'sex': 'string', 'age': 'string', 'decision': 'string', 'geo': 'string', 'TIME_PERIOD': 'string', 'GENCONV': \"Int64\", 'HUMSTAT': \"Int64\", 'SUB_PROT': \"Int64\", 'REJECTED': \"Int64\", 'TOTAL_POS': \"Int64\", 'TOTAL_APPS': \"Int64\", \"POS_RATE\": \"Float64\"}, keep_default_na=False, na_values=['nan'])\n",
    "\n",
    "##remove partial 2023-Q3 Data\n",
    "df = df[df[\"TIME_PERIOD\"] != \"2023-Q3\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500d090",
   "metadata": {},
   "source": [
    "## 1. Introduce Lagged Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5da77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizen</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>GENCONV</th>\n",
       "      <th>HUMSTAT</th>\n",
       "      <th>SUB_PROT</th>\n",
       "      <th>REJECTED</th>\n",
       "      <th>TOTAL_POS</th>\n",
       "      <th>...</th>\n",
       "      <th>TOTAL_POS - lag 7 quarters</th>\n",
       "      <th>TOTAL_POS - lag 8 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 1 quarter</th>\n",
       "      <th>TOTAL_APPS - lag 2 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 3 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 4 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 5 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 6 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 7 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 8 quarters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2010-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2010-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2010-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2010-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2011-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221109</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221110</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221111</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221112</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221113</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6249150 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        citizen  sex     age geo TIME_PERIOD  GENCONV  HUMSTAT  SUB_PROT  \\\n",
       "8            AD    F     UNK  AT     2010-Q1        0        0         0   \n",
       "9            AD    F     UNK  AT     2010-Q2        0        0         0   \n",
       "10           AD    F     UNK  AT     2010-Q3        0        0         0   \n",
       "11           AD    F     UNK  AT     2010-Q4        0        0         0   \n",
       "12           AD    F     UNK  AT     2011-Q1        0        0         0   \n",
       "...         ...  ...     ...  ..         ...      ...      ...       ...   \n",
       "7221109      ZW  UNK  Y_LT14  UK     2019-Q3        0        0         0   \n",
       "7221110      ZW  UNK  Y_LT14  UK     2019-Q4        0        0         0   \n",
       "7221111      ZW  UNK  Y_LT14  UK     2020-Q1        0        0         0   \n",
       "7221112      ZW  UNK  Y_LT14  UK     2020-Q2        0        0         0   \n",
       "7221113      ZW  UNK  Y_LT14  UK     2020-Q3        0        0         0   \n",
       "\n",
       "         REJECTED  TOTAL_POS  ...  TOTAL_POS - lag 7 quarters  \\\n",
       "8               0          0  ...                           0   \n",
       "9               0          0  ...                           0   \n",
       "10              0          0  ...                           0   \n",
       "11              0          0  ...                           0   \n",
       "12              0          0  ...                           0   \n",
       "...           ...        ...  ...                         ...   \n",
       "7221109         0          0  ...                           0   \n",
       "7221110         0          0  ...                           0   \n",
       "7221111         0          0  ...                           0   \n",
       "7221112         0          0  ...                           0   \n",
       "7221113         0          0  ...                           0   \n",
       "\n",
       "         TOTAL_POS - lag 8 quarters  TOTAL_APPS - lag 1 quarter  \\\n",
       "8                                 0                           0   \n",
       "9                                 0                           0   \n",
       "10                                0                           0   \n",
       "11                                0                           0   \n",
       "12                                0                           0   \n",
       "...                             ...                         ...   \n",
       "7221109                           0                           0   \n",
       "7221110                           0                           0   \n",
       "7221111                           0                           0   \n",
       "7221112                           0                           0   \n",
       "7221113                           0                           0   \n",
       "\n",
       "         TOTAL_APPS - lag 2 quarters  TOTAL_APPS - lag 3 quarters  \\\n",
       "8                                  0                            0   \n",
       "9                                  0                            0   \n",
       "10                                 0                            0   \n",
       "11                                 0                            0   \n",
       "12                                 0                            0   \n",
       "...                              ...                          ...   \n",
       "7221109                            0                            0   \n",
       "7221110                            0                            0   \n",
       "7221111                            0                            0   \n",
       "7221112                            0                            0   \n",
       "7221113                            0                            0   \n",
       "\n",
       "         TOTAL_APPS - lag 4 quarters  TOTAL_APPS - lag 5 quarters  \\\n",
       "8                                  0                            0   \n",
       "9                                  0                            0   \n",
       "10                                 0                            0   \n",
       "11                                 0                            0   \n",
       "12                                 0                            0   \n",
       "...                              ...                          ...   \n",
       "7221109                            0                            0   \n",
       "7221110                            0                            0   \n",
       "7221111                            0                            0   \n",
       "7221112                            0                            0   \n",
       "7221113                            0                            0   \n",
       "\n",
       "         TOTAL_APPS - lag 6 quarters  TOTAL_APPS - lag 7 quarters  \\\n",
       "8                                  0                            0   \n",
       "9                                  0                            0   \n",
       "10                                 0                            0   \n",
       "11                                 0                            0   \n",
       "12                                 0                            0   \n",
       "...                              ...                          ...   \n",
       "7221109                            0                            0   \n",
       "7221110                            0                            0   \n",
       "7221111                            0                            0   \n",
       "7221112                            0                            0   \n",
       "7221113                            0                            0   \n",
       "\n",
       "         TOTAL_APPS - lag 8 quarters  \n",
       "8                                  0  \n",
       "9                                  0  \n",
       "10                                 0  \n",
       "11                                 0  \n",
       "12                                 0  \n",
       "...                              ...  \n",
       "7221109                            0  \n",
       "7221110                            0  \n",
       "7221111                            0  \n",
       "7221112                            0  \n",
       "7221113                            0  \n",
       "\n",
       "[6249150 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#****************************************************re-sort dataframe****************************************************\n",
    "\n",
    "sort_order = ['citizen', 'sex', 'age', 'geo', 'TIME_PERIOD']\n",
    "df = df.sort_values(by =sort_order) \n",
    "\n",
    "#*********************************************create sequential list of quarters****************************************************\n",
    "\n",
    "quarters = []\n",
    "for i in range(2008, 2024):\n",
    "    quarters.append(str(i) + \"-Q1\")\n",
    "    quarters.append(str(i) + \"-Q2\")\n",
    "    quarters.append(str(i) + \"-Q3\")\n",
    "    quarters.append(str(i) + \"-Q4\")\n",
    "\n",
    "#****************************************************lagged features****************************************************\n",
    "\n",
    "QUARTERS_OF_LAG = (4 * 2)\n",
    "\n",
    "def add_lagged_features(df, features, maintained_columns, QUARTERS_OF_LAG):\n",
    "    quarters = np.unique(df[\"TIME_PERIOD\"])\n",
    "    def lagged_features(target_var, lag_count, unit):\n",
    "        lagged = pd.DataFrame()\n",
    "        columns = []\n",
    "        for i in range(1, lag_count + 1):\n",
    "            lagged = pd.concat([lagged, target_var.shift(i)], axis=1)\n",
    "            name = target_var.name\n",
    "            if (i == 1):\n",
    "                columns.append(name + \" - lag \" + str(i) + \" \" + str(unit))\n",
    "            else:\n",
    "                columns.append(name + \" - lag \" + str(i) + \" \" + str(unit) + \"s\")\n",
    "        lagged.columns = columns\n",
    "        return lagged.astype('Int64')\n",
    "\n",
    "    #introduce lag for each feature\n",
    "    df_lagged = df\n",
    "    for f in features:\n",
    "        df_lagged = pd.concat([df_lagged, lagged_features(df[f], QUARTERS_OF_LAG, \"quarter\")], axis=1)\n",
    "\n",
    "    #remove all features with less than the lag amount of historical data\n",
    "    #df_lagged = df_lagged[df_lagged.eq()]\n",
    "    for i in range(0, QUARTERS_OF_LAG):\n",
    "        shift_eq = df_lagged.eq(df_lagged.shift())\n",
    "        keep = shift_eq[maintained_columns[0]]\n",
    "        for j in range(1, len(maintained_columns)):\n",
    "            keep = keep & shift_eq[maintained_columns[j]]\n",
    "        df_lagged = df_lagged[keep]\n",
    "        #print(\"lagged i\" + str(i) + \" of \" + str(QUARTERS_OF_LAG))\n",
    "    \n",
    "    return df_lagged\n",
    "\n",
    "df_lagged = add_lagged_features(df, [\"TOTAL_POS\", \"TOTAL_APPS\"], ['citizen', 'age', 'sex', 'geo'], QUARTERS_OF_LAG)\n",
    "\n",
    "df_lagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e5062",
   "metadata": {},
   "source": [
    "### Lagged Feature Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cfc60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] testing lagging function\n",
      "\t[+] basic lag tests passed\n",
      "\t[+] tests with shared times passed\n",
      "\t[+] tests with multiple start and end dates passed\n",
      "\t[+] \u001b[42mPASSED ALL\u001b[0m lagging tests\n"
     ]
    }
   ],
   "source": [
    "#***********************************************testing equivalence function****************************************************\n",
    "def equivalent_dfs(df1, df2):\n",
    "    return (df1.reset_index(drop=True) == df2.reset_index(drop=True)).all().all()\n",
    "\n",
    "#****************************************************lagging testing****************************************************\n",
    "print(\"[*] testing lagging function\")\n",
    "#simple tests\n",
    "tdf0_data = [['AR', 1, 1], ['AR', 2, 2], ['AR', 3, 3], ['AR', 4, 4], ['AR', 5, 5]]\n",
    "tdf0 = pd.DataFrame(data=tdf0_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf1_data = [['AR', 2, 2, 1], ['AR', 3, 3, 2], ['AR', 4, 4, 3], ['AR', 5, 5, 4]]\n",
    "tdf1 = pd.DataFrame(data=tdf1_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf2_data = [['AR', 3, 3, 2, 1], ['AR', 4, 4, 3, 2], ['AR', 5, 5, 4, 3]]\n",
    "tdf2 = pd.DataFrame(data=tdf2_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "tdf3_data = [['AR', 4, 4, 3, 2, 1], ['AR', 5, 5, 4, 3, 2]]\n",
    "tdf3 = pd.DataFrame(data=tdf3_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters', 'val - lag 3 quarters'])\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 1), \n",
    "                      tdf1), \"basic lag test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 2), \n",
    "                      tdf2), \"basic lag test failed, shift=2\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 3), \n",
    "                      tdf3), \"basic lag test failed, shift=3\"\n",
    "print(\"\\t[+] basic lag tests passed\")\n",
    "\n",
    "#more advanced tests\n",
    "tdf4_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "             ['NZ', 1, 11], ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15]]\n",
    "tdf4 = pd.DataFrame(data=tdf4_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf5_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "             ['NZ', 2, 12, 11], ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14]]\n",
    "tdf5 = pd.DataFrame(data=tdf5_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf6_data = [['AU', 3, 3, 2, 1], ['AU', 4, 4, 3, 2], ['AU', 5, 5, 4, 3],\n",
    "             ['NZ', 3, 13, 12, 11], ['NZ', 4, 14, 13, 12], ['NZ', 5, 15, 14, 13]]\n",
    "tdf6 = pd.DataFrame(data=tdf6_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf4, [\"val\"], ['citizen'], 1), \n",
    "                      tdf5), \"lag with shared times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf4, [\"val\"], ['citizen'], 2), \n",
    "                      tdf6), \"lag with shared times test failed, shift=2\"\n",
    "print(\"\\t[+] tests with shared times passed\")\n",
    "\n",
    "#very complicated tests\n",
    "tdf7_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "             ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15]]\n",
    "tdf7 = pd.DataFrame(data=tdf7_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf8_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "             ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14]]\n",
    "tdf8 = pd.DataFrame(data=tdf8_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf9_data = [['AU', 3, 3, 2, 1], ['AU', 4, 4, 3, 2], ['AU', 5, 5, 4, 3],\n",
    "             ['NZ', 4, 14, 13, 12], ['NZ', 5, 15, 14, 13]]\n",
    "tdf9 = pd.DataFrame(data=tdf9_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "tdf10_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "              ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15],\n",
    "              ['FJ', 3, 23], ['FJ', 4, 24], ['FJ', 5, 25], ['FJ', 6, 26], ['FJ', 7, 27], ['FJ', 8, 28],\n",
    "              ['WS', 4, 34], ['WS', 5, 35]]\n",
    "tdf10 = pd.DataFrame(data=tdf10_data, columns=['citizen', 'TIME_PERIOD', 'new_val'])\n",
    "tdf11_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "              ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14],\n",
    "              ['FJ', 4, 24, 23], ['FJ', 5, 25, 24], ['FJ', 6, 26, 25], ['FJ', 7, 27, 26], ['FJ', 8, 28, 27],\n",
    "              ['WS', 5, 35, 34]]\n",
    "tdf11 = pd.DataFrame(data=tdf11_data, columns=['citizen', 'TIME_PERIOD', 'new_val', 'new_val - lag 1 quarter'])\n",
    "tdf12_data = [['AU', 5, 5, 4, 3, 2, 1],\n",
    "              ['FJ', 7, 27, 26, 25, 24, 23], ['FJ', 8, 28, 27, 26, 25, 24]]\n",
    "tdf12 = pd.DataFrame(data=tdf12_data, columns=['citizen', 'TIME_PERIOD', 'new_val', 'new_val - lag 1 quarter', 'new_val - lag 2 quarters', 'new_val - lag 3 quarters', 'new_val - lag 4 quarters'])\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf7, [\"val\"], ['citizen'], 1), \n",
    "                      tdf8), \"lag with 2 different start times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf7, [\"val\"], ['citizen'], 2), \n",
    "                      tdf9), \"lag with 2 different start times test failed, shift=2\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf10, [\"new_val\"], ['citizen'], 1), \n",
    "                      tdf11), \"lag with many different start times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf10, [\"new_val\"], ['citizen'], 4), \n",
    "                      tdf12), \"lag with many different start times test failed, shift=4\"\n",
    "print(\"\\t[+] tests with multiple start and end dates passed\")\n",
    "\n",
    "print(\"\\t[+] \\x1b[42mPASSED ALL\\x1b[0m lagging tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd114121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d6700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb22ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1acfa54",
   "metadata": {},
   "source": [
    "## 2. Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ace99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************splitting****************************************************\n",
    "TARGET_VAR = \"REJECTED\"\n",
    "\n",
    "y = df_lagged[TARGET_VAR]\n",
    "X = df_lagged.drop(['GENCONV', 'HUMSTAT', 'SUB_PROT', 'REJECTED', 'TOTAL_POS'], axis=1)\n",
    "#PLAN:\n",
    "#of 62 quarters...\n",
    "#QUARTERS_OF_LAG are lost bc they wont have the needed lagged features\n",
    "    \n",
    "new_quarters = [q for q in quarters if q >= quarters[QUARTERS_OF_LAG]]\n",
    "quarter_count = len(new_quarters) - 1\n",
    "\n",
    "train_split = 0.6\n",
    "test_split = 0.2\n",
    "val_split = 0.2\n",
    "\n",
    "\n",
    "\n",
    "div_0 = new_quarters[0]\n",
    "div_1 = new_quarters[int(quarter_count * train_split)]\n",
    "div_2 = new_quarters[int(quarter_count * (train_split + test_split))]\n",
    "div_3 = new_quarters[quarter_count]\n",
    "    \n",
    "X_train = X[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)]\n",
    "y_train = y[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)]\n",
    "\n",
    "X_test = X[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)]\n",
    "y_test = y[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)]\n",
    "\n",
    "X_val = X[(div_2 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_3)]\n",
    "y_val = y[(div_2 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8420b7c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] checking train test val split\n",
      "\t[+] no overlap between train, test, or val TIME_PERIODS\n",
      "\t[+] train is 0.605 of datapoints which is within bounds of its 0.6 target\n",
      "\t[+] test  is 0.207 of datapoints which is within bounds of its 0.2 target\n",
      "\t[+] val   is 0.187 of datapoints which is within bounds of its 0.2 target\n",
      "\t[*] \u001b[42mPASSED ALL\u001b[0m train test val split tests\n"
     ]
    }
   ],
   "source": [
    "def check_split_sizes(X, train, test, val):\n",
    "    fails = 0\n",
    "    print(\"[*] checking train test val split\")\n",
    "    train_set_qs = set(train[\"TIME_PERIOD\"])\n",
    "    test_set_qs = set(test[\"TIME_PERIOD\"])\n",
    "    val_set_qs = set(val[\"TIME_PERIOD\"])\n",
    "    \n",
    "    #check for TIME_PERIOD overlap\n",
    "    shared = (train_set_qs & test_set_qs) | (val_set_qs & test_set_qs) | (train_set_qs & val_set_qs)\n",
    "    if (len(shared) != 0):\n",
    "        warnings.warn('\\t[-] overlap between train, test, or val time_periods')\n",
    "        fails+=1\n",
    "    else:\n",
    "        print(\"\\t[+] no overlap between train, test, or val TIME_PERIODS\")\n",
    "        \n",
    "    #check for a fairly even 60/20/20 split\n",
    "    NAMES = ['train', 'test ', 'val  ']\n",
    "    TARGETS = [0.6, 0.2, 0.2]\n",
    "    ALLOWED_FRACTION_ERROR = 0.02\n",
    "    sizes = [len(train) / len(X), len(test) / len(X), len(val) / len(X)]\n",
    "    for i in range(0, 3):\n",
    "        if (np.abs(sizes[i] - TARGETS[i]) < ALLOWED_FRACTION_ERROR):\n",
    "            print(\"\\t[+] \" + str(NAMES[i]) + \" is \" + str(np.round(sizes[i], 3)) + \" of datapoints which is within bounds of its \" + str(TARGETS[i]) + \" target\")\n",
    "        else:\n",
    "            warnings.warn(\"\\t[-] \" + str(NAMES[i]) + \" is \" + str(np.round(sizes[i], 3)) + \" of datapoints which is out of bounds\")\n",
    "            fails+=1\n",
    "\n",
    "    if (fails == 0):\n",
    "        print(\"\\t[*] \\x1b[42mPASSED ALL\\x1b[0m train test val split tests\")\n",
    "    else:\n",
    "        print(\"\\t[?] \\033[91mFAILED \" + str(fails) + \"\\033[0m train test val split tests\")\n",
    "        \n",
    "\n",
    "check_split_sizes(X, X_train, X_test, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d982fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0f57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b72b064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdadb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063c616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30ce7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25946758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b8071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d532059",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "650c131d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3783348, 22)\n",
      "(3783348, 240)\n",
      "[[ 0.  8.  1. ...  1.  0.  0.]\n",
      " [ 0.  9.  1. ...  1.  0.  0.]\n",
      " [ 0. 10.  1. ...  1.  0.  0.]\n",
      " ...\n",
      " [ 1. 38.  0. ...  0.  0.  1.]\n",
      " [ 1. 39.  0. ...  0.  0.  1.]\n",
      " [ 1. 40.  0. ...  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "#****************************************************feature scaling********************************************************\n",
    "\n",
    "ordinal_ftrs = ['age', 'TIME_PERIOD']\n",
    "ordinal_cats = [['UNK','Y_LT14','Y14-17','Y18-34','Y35-64','Y_GE65'], quarters]\n",
    "                                                                     #^^i'm using quarters not new_quarters here so that\n",
    "                                                                     #  the model can still tell where in history this q is\n",
    "onehot_ftrs = ['citizen', 'geo', 'sex']\n",
    "minmax_ftrs = []\n",
    "std_ftrs = []\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(categories = ordinal_cats), ordinal_ftrs),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)]) # for now we only preprocess \n",
    "                                                       # later on we will add other steps here\n",
    "\n",
    "\n",
    "X_train_prep = clf.fit_transform(X_train)\n",
    "X_val_prep = clf.transform(X_val)\n",
    "X_test_prep = clf.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train_prep.shape)\n",
    "print(X_train_prep)\n",
    "#X_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d55328c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Ridge\n\u001b[1;32m      2\u001b[0m ridge_param_grid \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      3\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel__alpha\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.03\u001b[39m, \u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m100\u001b[39m], \u001b[38;5;66;03m# no upper bound so the values are evenly spaced in log\u001b[39;00m\n\u001b[1;32m      4\u001b[0m             } \n\u001b[0;32m----> 6\u001b[0m ridge_test_scores, ridge_best_models \u001b[38;5;241m=\u001b[39m MLpipe_RMSE(preprocessor, Ridge, ridge_param_grid)\n",
      "Cell \u001b[0;32mIn[11], line 41\u001b[0m, in \u001b[0;36mMLpipe_RMSE\u001b[0;34m(preprocessor, ML_algo, param_grid)\u001b[0m\n\u001b[1;32m     33\u001b[0m pipe \u001b[38;5;241m=\u001b[39m Pipeline(steps\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     34\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpreprocess\u001b[39m\u001b[38;5;124m'\u001b[39m, preprocessor),\n\u001b[1;32m     35\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, ML_algo())\n\u001b[1;32m     36\u001b[0m     ])\n\u001b[1;32m     38\u001b[0m grid \u001b[38;5;241m=\u001b[39m GridSearchCV(pipe, param_grid\u001b[38;5;241m=\u001b[39mparam_grid,scoring \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_root_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, \\\n\u001b[1;32m     39\u001b[0m                     return_train_score \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 41\u001b[0m grid\u001b[38;5;241m.\u001b[39mfit(X_val, y_val)\n\u001b[1;32m     43\u001b[0m results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(grid\u001b[38;5;241m.\u001b[39mcv_results_)\n\u001b[1;32m     45\u001b[0m best_models\u001b[38;5;241m.\u001b[39mappend(grid)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[38;5;241m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[38;5;241m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[38;5;241m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[38;5;129;01min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;28menumerate\u001b[39m(candidate_params), \u001b[38;5;28menumerate\u001b[39m(cv\u001b[38;5;241m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1098\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1097\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1098\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretrieve()\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:975\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    974\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 975\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout))\n\u001b[1;32m    976\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    977\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:567\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    565\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 567\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m future\u001b[38;5;241m.\u001b[39mresult(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/concurrent/futures/_base.py:451\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_param_grid = {\n",
    "            'model__alpha': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100], # no upper bound so the values are evenly spaced in log\n",
    "            } \n",
    "\n",
    "ridge_test_scores, ridge_best_models = MLpipe_RMSE(preprocessor, Ridge, ridge_param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fba1c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************training models****************************************************\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# function for the ML pipeline as outlined above \n",
    "def MLpipe_RMSE(preprocessor, ML_algo, param_grid):\n",
    "    '''\n",
    "    !This function splits the data to other/test (80/20) and then applies KFold with 4 folds to other.\n",
    "    !The RMSE is minimized in cross-validation.\n",
    "\n",
    "    !You should:\n",
    "\n",
    "    !1. Loop through 10 different random states\n",
    "    !2. Split your data \n",
    "    !3. Fit a model using GridSearchCV with KFold and the predefined Preprocessor \n",
    "    !4. Calculate the model's error on the test set \n",
    "    !5. Return a list of 10 test scores and 10 best models \n",
    "    '''\n",
    "    \n",
    "    # lists to be returned \n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "    \n",
    "    # your code here...\n",
    "    for RANDOM_STATE in range(0, 10):\n",
    "        pipe = Pipeline(steps=[\n",
    "                ('preprocess', preprocessor),\n",
    "                ('model', ML_algo())\n",
    "            ])\n",
    "\n",
    "        grid = GridSearchCV(pipe, param_grid=param_grid,scoring = 'neg_root_mean_squared_error', \\\n",
    "                            return_train_score = True, n_jobs=-2, verbose=True)\n",
    "\n",
    "        grid.fit(X_val, y_val)\n",
    "        \n",
    "        results = pd.DataFrame(grid.cv_results_)\n",
    "        \n",
    "        best_models.append(grid)\n",
    "        y_pred = grid.predict(X_test)\n",
    "        test_scores.append(np.sqrt(mean_squared_error(y_pred, y_test)))\n",
    "\n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab34edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
