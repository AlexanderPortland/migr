{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10aa6b5c",
   "metadata": {},
   "source": [
    "# Splitting, Preprocessing and Model Development\n",
    "This notebook is used for:\n",
    "\n",
    "\n",
    "### Declaring Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "318f1efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import ticker\n",
    "from matplotlib.colors import LogNorm, Normalize\n",
    "import sklearn\n",
    "import time\n",
    "import datetime\n",
    "import joblib\n",
    "import warnings\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534a4beb",
   "metadata": {},
   "source": [
    "### Color Palette & Typeface Sizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9835e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "YELLOW = '#F2DC5D'\n",
    "GREEN = '#9BC53D'\n",
    "DARK_GREEN = '#597222'\n",
    "RED = '#C3423F'\n",
    "LIGHT_BLUE = '#2596BE'\n",
    "GRAY = '#666666'\n",
    "\n",
    "AXIS_SIZE = 12\n",
    "TITLE_SIZE = 16\n",
    "DESCRIPTION_SIZE = 9\n",
    "FIGURE_SIZE = (10*2/3,6*2/3)\n",
    "\n",
    "RANDOM_STATE = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f849d3c5",
   "metadata": {},
   "source": [
    "### Import Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23f2f082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizen</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>GENCONV</th>\n",
       "      <th>HUMSTAT</th>\n",
       "      <th>SUB_PROT</th>\n",
       "      <th>REJECTED</th>\n",
       "      <th>TOTAL_POS</th>\n",
       "      <th>TOTAL_APPS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2008-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221109</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221110</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221111</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221112</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221113</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7213806 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        citizen  sex     age geo TIME_PERIOD  GENCONV  HUMSTAT  SUB_PROT  \\\n",
       "0            AD    F     UNK  AT     2008-Q1        0        0         0   \n",
       "1            AD    F     UNK  AT     2008-Q2        0        0         0   \n",
       "2            AD    F     UNK  AT     2008-Q3        0        0         0   \n",
       "3            AD    F     UNK  AT     2008-Q4        0        0         0   \n",
       "4            AD    F     UNK  AT     2009-Q1        0        0         0   \n",
       "...         ...  ...     ...  ..         ...      ...      ...       ...   \n",
       "7221109      ZW  UNK  Y_LT14  UK     2019-Q3        0        0         0   \n",
       "7221110      ZW  UNK  Y_LT14  UK     2019-Q4        0        0         0   \n",
       "7221111      ZW  UNK  Y_LT14  UK     2020-Q1        0        0         0   \n",
       "7221112      ZW  UNK  Y_LT14  UK     2020-Q2        0        0         0   \n",
       "7221113      ZW  UNK  Y_LT14  UK     2020-Q3        0        0         0   \n",
       "\n",
       "         REJECTED  TOTAL_POS  TOTAL_APPS  \n",
       "0               0          0           0  \n",
       "1               0          0           0  \n",
       "2               0          0           0  \n",
       "3               0          0           0  \n",
       "4               0          0           0  \n",
       "...           ...        ...         ...  \n",
       "7221109         0          0           0  \n",
       "7221110         0          0           0  \n",
       "7221111         0          0           0  \n",
       "7221112         0          0           0  \n",
       "7221113         0          0           0  \n",
       "\n",
       "[7213806 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#****************************************************import dataset****************************************************\n",
    "df = pd.read_csv('../data/final.csv', dtype={'citizen': 'string', 'sex': 'string', 'age': 'string', 'decision': 'string', 'geo': 'string', 'TIME_PERIOD': 'string', 'GENCONV': \"Int64\", 'HUMSTAT': \"Int64\", 'SUB_PROT': \"Int64\", 'REJECTED': \"Int64\", 'TOTAL_POS': \"Int64\", 'TOTAL_APPS': \"Int64\", \"POS_RATE\": \"Float64\"}, keep_default_na=False, na_values=['nan'])\n",
    "\n",
    "##remove partial 2023-Q3 Data\n",
    "df = df[df[\"TIME_PERIOD\"] != \"2023-Q3\"]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5500d090",
   "metadata": {},
   "source": [
    "## 1. Introduce Lagged Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a5da77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>citizen</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>geo</th>\n",
       "      <th>TIME_PERIOD</th>\n",
       "      <th>GENCONV</th>\n",
       "      <th>HUMSTAT</th>\n",
       "      <th>SUB_PROT</th>\n",
       "      <th>REJECTED</th>\n",
       "      <th>TOTAL_POS</th>\n",
       "      <th>TOTAL_APPS</th>\n",
       "      <th>TOTAL_POS - lag 1 quarter</th>\n",
       "      <th>TOTAL_POS - lag 2 quarters</th>\n",
       "      <th>TOTAL_POS - lag 3 quarters</th>\n",
       "      <th>TOTAL_POS - lag 4 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 1 quarter</th>\n",
       "      <th>TOTAL_APPS - lag 2 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 3 quarters</th>\n",
       "      <th>TOTAL_APPS - lag 4 quarters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2009-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AD</td>\n",
       "      <td>F</td>\n",
       "      <td>UNK</td>\n",
       "      <td>AT</td>\n",
       "      <td>2010-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221109</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221110</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2019-Q4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221111</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221112</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7221113</th>\n",
       "      <td>ZW</td>\n",
       "      <td>UNK</td>\n",
       "      <td>Y_LT14</td>\n",
       "      <td>UK</td>\n",
       "      <td>2020-Q3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6731478 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        citizen  sex     age geo TIME_PERIOD  GENCONV  HUMSTAT  SUB_PROT  \\\n",
       "4            AD    F     UNK  AT     2009-Q1        0        0         0   \n",
       "5            AD    F     UNK  AT     2009-Q2        0        0         0   \n",
       "6            AD    F     UNK  AT     2009-Q3        0        0         0   \n",
       "7            AD    F     UNK  AT     2009-Q4        0        0         0   \n",
       "8            AD    F     UNK  AT     2010-Q1        0        0         0   \n",
       "...         ...  ...     ...  ..         ...      ...      ...       ...   \n",
       "7221109      ZW  UNK  Y_LT14  UK     2019-Q3        0        0         0   \n",
       "7221110      ZW  UNK  Y_LT14  UK     2019-Q4        0        0         0   \n",
       "7221111      ZW  UNK  Y_LT14  UK     2020-Q1        0        0         0   \n",
       "7221112      ZW  UNK  Y_LT14  UK     2020-Q2        0        0         0   \n",
       "7221113      ZW  UNK  Y_LT14  UK     2020-Q3        0        0         0   \n",
       "\n",
       "         REJECTED  TOTAL_POS  TOTAL_APPS  TOTAL_POS - lag 1 quarter  \\\n",
       "4               0          0           0                          0   \n",
       "5               0          0           0                          0   \n",
       "6               0          0           0                          0   \n",
       "7               0          0           0                          0   \n",
       "8               0          0           0                          0   \n",
       "...           ...        ...         ...                        ...   \n",
       "7221109         0          0           0                          0   \n",
       "7221110         0          0           0                          0   \n",
       "7221111         0          0           0                          0   \n",
       "7221112         0          0           0                          0   \n",
       "7221113         0          0           0                          0   \n",
       "\n",
       "         TOTAL_POS - lag 2 quarters  TOTAL_POS - lag 3 quarters  \\\n",
       "4                                 0                           0   \n",
       "5                                 0                           0   \n",
       "6                                 0                           0   \n",
       "7                                 0                           0   \n",
       "8                                 0                           0   \n",
       "...                             ...                         ...   \n",
       "7221109                           0                           0   \n",
       "7221110                           0                           0   \n",
       "7221111                           0                           0   \n",
       "7221112                           0                           0   \n",
       "7221113                           0                           0   \n",
       "\n",
       "         TOTAL_POS - lag 4 quarters  TOTAL_APPS - lag 1 quarter  \\\n",
       "4                                 0                           0   \n",
       "5                                 0                           0   \n",
       "6                                 0                           0   \n",
       "7                                 0                           0   \n",
       "8                                 0                           0   \n",
       "...                             ...                         ...   \n",
       "7221109                           0                           0   \n",
       "7221110                           0                           0   \n",
       "7221111                           0                           0   \n",
       "7221112                           0                           0   \n",
       "7221113                           0                           0   \n",
       "\n",
       "         TOTAL_APPS - lag 2 quarters  TOTAL_APPS - lag 3 quarters  \\\n",
       "4                                  0                            0   \n",
       "5                                  0                            0   \n",
       "6                                  0                            0   \n",
       "7                                  0                            0   \n",
       "8                                  0                            0   \n",
       "...                              ...                          ...   \n",
       "7221109                            0                            0   \n",
       "7221110                            0                            0   \n",
       "7221111                            0                            0   \n",
       "7221112                            0                            0   \n",
       "7221113                            0                            0   \n",
       "\n",
       "         TOTAL_APPS - lag 4 quarters  \n",
       "4                                  0  \n",
       "5                                  0  \n",
       "6                                  0  \n",
       "7                                  0  \n",
       "8                                  0  \n",
       "...                              ...  \n",
       "7221109                            0  \n",
       "7221110                            0  \n",
       "7221111                            0  \n",
       "7221112                            0  \n",
       "7221113                            0  \n",
       "\n",
       "[6731478 rows x 19 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#****************************************************re-sort dataframe****************************************************\n",
    "\n",
    "sort_order = ['citizen', 'sex', 'age', 'geo', 'TIME_PERIOD']\n",
    "df = df.sort_values(by =sort_order) \n",
    "\n",
    "#*********************************************create sequential list of quarters****************************************************\n",
    "\n",
    "quarters = []\n",
    "for i in range(2008, 2024):\n",
    "    quarters.append(str(i) + \"-Q1\")\n",
    "    quarters.append(str(i) + \"-Q2\")\n",
    "    quarters.append(str(i) + \"-Q3\")\n",
    "    quarters.append(str(i) + \"-Q4\")\n",
    "\n",
    "#****************************************************lagged features****************************************************\n",
    "\n",
    "QUARTERS_OF_LAG = (4 * 1)\n",
    "\n",
    "def add_lagged_features(df, features, maintained_columns, QUARTERS_OF_LAG):\n",
    "    quarters = np.unique(df[\"TIME_PERIOD\"])\n",
    "    def lagged_features(target_var, lag_count, unit):\n",
    "        lagged = pd.DataFrame()\n",
    "        columns = []\n",
    "        for i in range(1, lag_count + 1):\n",
    "            lagged = pd.concat([lagged, target_var.shift(i)], axis=1)\n",
    "            name = target_var.name\n",
    "            if (i == 1):\n",
    "                columns.append(name + \" - lag \" + str(i) + \" \" + str(unit))\n",
    "            else:\n",
    "                columns.append(name + \" - lag \" + str(i) + \" \" + str(unit) + \"s\")\n",
    "        lagged.columns = columns\n",
    "        return lagged.astype('Int64')\n",
    "\n",
    "    #introduce lag for each feature\n",
    "    df_lagged = df\n",
    "    for f in features:\n",
    "        df_lagged = pd.concat([df_lagged, lagged_features(df[f], QUARTERS_OF_LAG, \"quarter\")], axis=1)\n",
    "\n",
    "    #remove all features with less than the lag amount of historical data\n",
    "    #df_lagged = df_lagged[df_lagged.eq()]\n",
    "    for i in range(0, QUARTERS_OF_LAG):\n",
    "        shift_eq = df_lagged.eq(df_lagged.shift())\n",
    "        keep = shift_eq[maintained_columns[0]]\n",
    "        for j in range(1, len(maintained_columns)):\n",
    "            keep = keep & shift_eq[maintained_columns[j]]\n",
    "        df_lagged = df_lagged[keep]\n",
    "        #print(\"lagged i\" + str(i) + \" of \" + str(QUARTERS_OF_LAG))\n",
    "    \n",
    "    return df_lagged\n",
    "\n",
    "df_lagged = add_lagged_features(df, [\"TOTAL_POS\", \"TOTAL_APPS\"], ['citizen', 'age', 'sex', 'geo'], QUARTERS_OF_LAG)\n",
    "\n",
    "df_lagged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419e5062",
   "metadata": {},
   "source": [
    "### Lagged Feature Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45cfc60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*] testing lagging function\n",
      "\t[+] basic lag tests passed\n",
      "\t[+] tests with shared times passed\n",
      "\t[+] tests with multiple start and end dates passed\n",
      "\t[+] \u001b[42mPASSED ALL\u001b[0m lagging tests\n"
     ]
    }
   ],
   "source": [
    "#***********************************************testing equivalence function****************************************************\n",
    "def equivalent_dfs(df1, df2):\n",
    "    return (df1.reset_index(drop=True) == df2.reset_index(drop=True)).all().all()\n",
    "\n",
    "#****************************************************lagging testing****************************************************\n",
    "print(\"[*] testing lagging function\")\n",
    "#simple tests\n",
    "tdf0_data = [['AR', 1, 1], ['AR', 2, 2], ['AR', 3, 3], ['AR', 4, 4], ['AR', 5, 5]]\n",
    "tdf0 = pd.DataFrame(data=tdf0_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf1_data = [['AR', 2, 2, 1], ['AR', 3, 3, 2], ['AR', 4, 4, 3], ['AR', 5, 5, 4]]\n",
    "tdf1 = pd.DataFrame(data=tdf1_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf2_data = [['AR', 3, 3, 2, 1], ['AR', 4, 4, 3, 2], ['AR', 5, 5, 4, 3]]\n",
    "tdf2 = pd.DataFrame(data=tdf2_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "tdf3_data = [['AR', 4, 4, 3, 2, 1], ['AR', 5, 5, 4, 3, 2]]\n",
    "tdf3 = pd.DataFrame(data=tdf3_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters', 'val - lag 3 quarters'])\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 1), \n",
    "                      tdf1), \"basic lag test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 2), \n",
    "                      tdf2), \"basic lag test failed, shift=2\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf0, [\"val\"], ['citizen'], 3), \n",
    "                      tdf3), \"basic lag test failed, shift=3\"\n",
    "print(\"\\t[+] basic lag tests passed\")\n",
    "\n",
    "#more advanced tests\n",
    "tdf4_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "             ['NZ', 1, 11], ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15]]\n",
    "tdf4 = pd.DataFrame(data=tdf4_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf5_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "             ['NZ', 2, 12, 11], ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14]]\n",
    "tdf5 = pd.DataFrame(data=tdf5_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf6_data = [['AU', 3, 3, 2, 1], ['AU', 4, 4, 3, 2], ['AU', 5, 5, 4, 3],\n",
    "             ['NZ', 3, 13, 12, 11], ['NZ', 4, 14, 13, 12], ['NZ', 5, 15, 14, 13]]\n",
    "tdf6 = pd.DataFrame(data=tdf6_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf4, [\"val\"], ['citizen'], 1), \n",
    "                      tdf5), \"lag with shared times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf4, [\"val\"], ['citizen'], 2), \n",
    "                      tdf6), \"lag with shared times test failed, shift=2\"\n",
    "print(\"\\t[+] tests with shared times passed\")\n",
    "\n",
    "#very complicated tests\n",
    "tdf7_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "             ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15]]\n",
    "tdf7 = pd.DataFrame(data=tdf7_data, columns=['citizen', 'TIME_PERIOD', 'val'])\n",
    "tdf8_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "             ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14]]\n",
    "tdf8 = pd.DataFrame(data=tdf8_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter'])\n",
    "tdf9_data = [['AU', 3, 3, 2, 1], ['AU', 4, 4, 3, 2], ['AU', 5, 5, 4, 3],\n",
    "             ['NZ', 4, 14, 13, 12], ['NZ', 5, 15, 14, 13]]\n",
    "tdf9 = pd.DataFrame(data=tdf9_data, columns=['citizen', 'TIME_PERIOD', 'val', 'val - lag 1 quarter', 'val - lag 2 quarters'])\n",
    "tdf10_data = [['AU', 1, 1], ['AU', 2, 2], ['AU', 3, 3], ['AU', 4, 4], ['AU', 5, 5],\n",
    "              ['NZ', 2, 12], ['NZ', 3, 13], ['NZ', 4, 14], ['NZ', 5, 15],\n",
    "              ['FJ', 3, 23], ['FJ', 4, 24], ['FJ', 5, 25], ['FJ', 6, 26], ['FJ', 7, 27], ['FJ', 8, 28],\n",
    "              ['WS', 4, 34], ['WS', 5, 35]]\n",
    "tdf10 = pd.DataFrame(data=tdf10_data, columns=['citizen', 'TIME_PERIOD', 'new_val'])\n",
    "tdf11_data = [['AU', 2, 2, 1], ['AU', 3, 3, 2], ['AU', 4, 4, 3], ['AU', 5, 5, 4],\n",
    "              ['NZ', 3, 13, 12], ['NZ', 4, 14, 13], ['NZ', 5, 15, 14],\n",
    "              ['FJ', 4, 24, 23], ['FJ', 5, 25, 24], ['FJ', 6, 26, 25], ['FJ', 7, 27, 26], ['FJ', 8, 28, 27],\n",
    "              ['WS', 5, 35, 34]]\n",
    "tdf11 = pd.DataFrame(data=tdf11_data, columns=['citizen', 'TIME_PERIOD', 'new_val', 'new_val - lag 1 quarter'])\n",
    "tdf12_data = [['AU', 5, 5, 4, 3, 2, 1],\n",
    "              ['FJ', 7, 27, 26, 25, 24, 23], ['FJ', 8, 28, 27, 26, 25, 24]]\n",
    "tdf12 = pd.DataFrame(data=tdf12_data, columns=['citizen', 'TIME_PERIOD', 'new_val', 'new_val - lag 1 quarter', 'new_val - lag 2 quarters', 'new_val - lag 3 quarters', 'new_val - lag 4 quarters'])\n",
    "\n",
    "assert equivalent_dfs(add_lagged_features(tdf7, [\"val\"], ['citizen'], 1), \n",
    "                      tdf8), \"lag with 2 different start times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf7, [\"val\"], ['citizen'], 2), \n",
    "                      tdf9), \"lag with 2 different start times test failed, shift=2\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf10, [\"new_val\"], ['citizen'], 1), \n",
    "                      tdf11), \"lag with many different start times test failed, shift=1\"\n",
    "assert equivalent_dfs(add_lagged_features(tdf10, [\"new_val\"], ['citizen'], 4), \n",
    "                      tdf12), \"lag with many different start times test failed, shift=4\"\n",
    "print(\"\\t[+] tests with multiple start and end dates passed\")\n",
    "\n",
    "print(\"\\t[+] \\x1b[42mPASSED ALL\\x1b[0m lagging tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd114121",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d6700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb22ec7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1acfa54",
   "metadata": {},
   "source": [
    "## 2. Dataset Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ace99b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************splitting****************************************************\n",
    "TARGET_VAR = \"TOTAL_POS\"\n",
    "\n",
    "y = df_lagged[TARGET_VAR]\n",
    "X = df_lagged.drop(['GENCONV', 'HUMSTAT', 'SUB_PROT', 'REJECTED', 'TOTAL_POS'], axis=1)\n",
    "#PLAN:\n",
    "#of 62 quarters...\n",
    "#QUARTERS_OF_LAG are lost bc they wont have the needed lagged features\n",
    "    \n",
    "new_quarters = [q for q in quarters if q >= quarters[QUARTERS_OF_LAG]]\n",
    "quarter_count = len(new_quarters) - 1\n",
    "\n",
    "TRAIN_PORTION = 0.6\n",
    "VAL_PORTION = 0.2\n",
    "TEST_PORTION = 0.2\n",
    "\n",
    "#take out last portion of quarters for testing\n",
    "#div_0 = new_quarters[0]\n",
    "#div_1 = new_quarters[int(quarter_count * train_split)]\n",
    "div_2 = new_quarters[int(quarter_count * (1 - TEST_PORTION))]\n",
    "div_3 = new_quarters[quarter_count]\n",
    "\n",
    "#seperate out test section\n",
    "X_test = X[(div_2 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_3)]\n",
    "y_test = y[(div_2 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd81e4b",
   "metadata": {},
   "source": [
    "### Evaluation Functions (for cross-validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5f29819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y_pred, y_true):\n",
    "    return np.sqrt(((y_pred - y_true) ** 2).sum() / len(y_pred))\n",
    "\n",
    "def BASELINE_RMSE(y_true):\n",
    "    return ALL_ZERO_BASELINE(y_true)\n",
    "\n",
    "def ALL_ZERO_BASELINE(y_true):\n",
    "    return np.sqrt(((y_true) ** 2).sum() / len(y_true))\n",
    "\n",
    "def ALL_ONE_BASELINE(y_true):\n",
    "    return np.sqrt(((1 - y_true) ** 2).sum() / len(y_true))\n",
    "\n",
    "def ALL_MEAN_BASELINE(y_train, y_true):\n",
    "    mean = y_train.mean()\n",
    "    return np.sqrt(((mean - y_true) ** 2).sum() / len(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a4a15",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d25fb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TIMESTAMP_STR():\n",
    "    dt = datetime.datetime.now()\n",
    "    txt = \"{hour}:{minute:02.0f} on {day}-{month}-{year}\"\n",
    "    return txt.format(hour=dt.hour, minute=dt.minute, day=dt.day, month=dt.month, year=dt.year)\n",
    "\n",
    "def DF_ALL_PREDICTED(model):\n",
    "    df_new = df\n",
    "    df_new[\"TOTAL_APPS_PRED\"] = model.predict(X)\n",
    "\n",
    "UPDATE = True\n",
    "def Status_Update(t, message):\n",
    "    my_time = time.time()\n",
    "    if UPDATE:\n",
    "        print(str(message) + \" \\t-- in \" + str(time.time() - t) + \"s\")\n",
    "    return time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f840ef3",
   "metadata": {},
   "source": [
    "### General Model-Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5278a1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLPipe_TimeSeries_RMSE(X, y, preprocessor, ML_algo, param_grid):\n",
    "    ALGO_NAME = str(ML_algo)[str(ML_algo).rindex('.')+1:-2]\n",
    "    MODEL_NAME = \"{algo}({time})\".format(algo=ALGO_NAME, time=TIMESTAMP_STR())\n",
    "    NUM_FOLDS = np.round(TRAIN_PORTION / VAL_PORTION).astype(int)\n",
    "    RANDOM_STATE = 14\n",
    "    print(\"[!] looking at model: \" + str(MODEL_NAME))\n",
    "    \n",
    "    print(\"\\t[*] doing initial dataset splitting\")\n",
    "    \n",
    "    #opt check 2\n",
    "    X_trains = []\n",
    "    y_trains = []\n",
    "    X_vals = []\n",
    "    y_vals = []\n",
    "    for i in range(1, NUM_FOLDS + 1):\n",
    "        train_portion = np.round(i * VAL_PORTION, 2)\n",
    "        div_0 = new_quarters[0]\n",
    "        div_1 = new_quarters[int(quarter_count * train_portion)]\n",
    "        div_2 = new_quarters[int(quarter_count * (train_portion + VAL_PORTION))]\n",
    "\n",
    "        X_trains.append(X[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "        y_trains.append(y[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "        X_vals.append(X[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "        y_vals.append(y[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "        print(\"\\t\\t[+] fold \" + str(i))\n",
    "    \n",
    "    param_scores = []\n",
    "    param_models = []\n",
    "    for p in param_grid:\n",
    "        T_PARAM_START = time.time()\n",
    "        fold_scores = []\n",
    "        print(\"\\t[*] looking at hyperparameters \" + str(p))\n",
    "        for i in range(1, NUM_FOLDS + 1):\n",
    "            T_FOLD_START = time.time()\n",
    "            #ADD OPTIMIZATION HERE:\n",
    "                #[2] NO NEED TO CONSTANTLY REDIVIDE THE DATA, SAME THREE FOLDS WILL BE USED EACH TIME REGARDLES OF HYPERPARAMAETERS\n",
    "                #[1] NO NEED TO CHECK FUTURE FOLDS IF EVEN A SCORE OF ZERO WOULDN'T BRING IT BELOW A BETTER FOUND PARAMETER ARRANGEMENT\n",
    "            train_portion = np.round(i * VAL_PORTION, 2)\n",
    "            \n",
    "            #opt check 1\n",
    "            if (i > 0 & len(param_scores) > 0):\n",
    "                best_param_score = param_scores[np.argmin(param_scores)]\n",
    "                if ((best_param_score * 3) < np.sum(fold_scores)):\n",
    "                    print(\"[!] best average score I could get with \" + str(np.sum(fold_scores)) + \" score already is worse than a previous params score of \" + str(best_param_score) + \", so giving up\")\n",
    "\n",
    "            mini_t = time.time()\n",
    "            \n",
    "            X_train = X_trains[i - 1]\n",
    "            y_train = y_trains[i - 1]\n",
    "            X_val = X_vals[i - 1]\n",
    "            y_val = y_vals[i - 1]\n",
    "            \n",
    "            if False:\n",
    "                PORTION_OF_POINTS = 0.001\n",
    "                X_train = X_train.sample(np.floor((len(X_train) * PORTION_OF_POINTS)).astype(int), random_state = RANDOM_STATE)\n",
    "                y_train = y_train.loc[X_train.index]\n",
    "                X_val = X_val.sample(np.floor((len(X_val) * PORTION_OF_POINTS)).astype(int), random_state = RANDOM_STATE)\n",
    "                y_val = y_val.loc[X_val.index]\n",
    "            \n",
    "            mini_t = Status_Update(mini_t, \"split data\")\n",
    "\n",
    "            #make pipeline\n",
    "            if (ALGO_NAME == \"SVR\"):\n",
    "                algo = ML_algo(**p)\n",
    "            else:\n",
    "                algo = ML_algo(**p, random_state = RANDOM_STATE)\n",
    "            \n",
    "            #print(algo)\n",
    "            pipe = Pipeline(steps=[\n",
    "                        ('preprocess', preprocessor),\n",
    "                        ('model', algo)\n",
    "                    ], verbose=True)\n",
    "            \n",
    "            mini_t = Status_Update(mini_t, \"made pipeline\")\n",
    "            #print(X_train)\n",
    "            \n",
    "            pipe.fit(X_train, y_train)\n",
    "            mini_t = Status_Update(mini_t, \"fit pipeline\")\n",
    "            \n",
    "            y_pred = pipe.predict(X_val)\n",
    "            score = RMSE(y_pred, y_val)\n",
    "            \n",
    "            fold_scores.append(score)\n",
    "            T_FOLD_END = time.time()\n",
    "            T_FOLD_ELAPSED = T_FOLD_END - T_FOLD_START\n",
    "            mini_t = Status_Update(mini_t, \"eval pipeline\")\n",
    "            print(\"\\t\\t[*] fold \" + str(i) + \" complete (test score of \" + str(score) + \") -- in \" + str(np.round(T_FOLD_ELAPSED, 3)) + \"s\")\n",
    "        score = np.mean(fold_scores)\n",
    "        param_scores.append(score)\n",
    "        param_models.append(pipe)\n",
    "        \n",
    "        T_PARAM_END = time.time()\n",
    "        T_PARAM_ELAPSED = T_PARAM_END - T_PARAM_START\n",
    "        print(\"\\t\\t[+] final score for params of \" + str(score) + \" -- in \" + str(np.round(T_PARAM_ELAPSED, 3)) + \"s\")\n",
    "        \n",
    "        if (np.argmin(param_scores) == (len(param_scores) - 1)):\n",
    "            best_model = param_models[np.argmin(param_scores)]\n",
    "            print(\"\\t\\t[!] new best param configuration, so saving model to path\")\n",
    "            path = \"../results/\" + MODEL_NAME + \".pkl\"\n",
    "            joblib.dump(best_model, path, compress = 1)\n",
    "            print(\"\\t\\t\\t[+] saved model to \" + str(path))\n",
    "        \n",
    "        \n",
    "    i_best = np.argmin(param_scores)\n",
    "    best_score = param_scores[i_best]\n",
    "    best_params = param_grid[i_best]\n",
    "    best_model = param_models[i_best]\n",
    "    print(\"\\t[+] best param configuration of \" + str(best_params) + \" found with score \" + str(best_score))\n",
    "    path = \"../results/\" + MODEL_NAME + \".pkl\"\n",
    "    joblib.dump(best_model, path, compress = 1)\n",
    "    print(\"\\t[+] saved model to \" + str(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9f0d0e",
   "metadata": {},
   "source": [
    "### Importing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34d0df76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "#MODELS TO TEST:\n",
    "#[IP] LASSO\n",
    "#[T] RIDGE\n",
    "#[Q] ELASTIC NET\n",
    "#[IP] RF\n",
    "#[] SVR\n",
    "#[] XGBoost\n",
    "#[] KNN??\n",
    "\n",
    "#T: Trained\n",
    "#IP: In Progress\n",
    "#Q: Queued"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639c126f",
   "metadata": {},
   "source": [
    "### Training Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6340e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "LASSO_PARAM_GRID = ParameterGrid({\n",
    "            'alpha': np.geomspace(0.01, 10000, 12), # no upper bound so the values are evenly spaced in log\n",
    "            })\n",
    "\n",
    "ELASTIC_PARAM_GRID = ParameterGrid({\n",
    "            'alpha': np.geomspace(0.1, 10000, 12), # no upper bound so the values are evenly spaced in log\n",
    "            'l1_ratio': np.linspace(0.2, 1, 9)\n",
    "            })\n",
    "\n",
    "#MLPipe_TimeSeries_RMSE(X, y, preprocessor, ElasticNet, ELASTIC_PARAM_GRID)\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, Lasso, LASSO_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b522c45c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] looking at model: LinearSVR(13:54 on 3-12-2023)\n",
      "\t[*] doing initial dataset splitting\n",
      "\t\t[+] fold 1\n",
      "\t\t[+] fold 2\n",
      "\t\t[+] fold 3\n",
      "\t[*] looking at hyperparameters {'C': 0.1, 'dual': 'auto'}\n",
      "split data \t-- in 2.7179718017578125e-05s\n",
      "made pipeline \t-- in 0.0001919269561767578s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total= 5.6min\n",
      "fit pipeline \t-- in 337.15336298942566s\n",
      "eval pipeline \t-- in 5.750520706176758s\n",
      "\t\t[*] fold 1 complete (test score of 4.7585265430888875) -- in 342.904s\n",
      "split data \t-- in 6.9141387939453125e-06s\n",
      "made pipeline \t-- in 0.00014901161193847656s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   8.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=12.8min\n",
      "fit pipeline \t-- in 773.7149360179901s\n",
      "eval pipeline \t-- in 6.197703123092651s\n",
      "\t\t[*] fold 2 complete (test score of 29.199649097801224) -- in 779.913s\n",
      "split data \t-- in 1.6689300537109375e-06s\n",
      "made pipeline \t-- in 0.00013208389282226562s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  14.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=22.3min\n",
      "fit pipeline \t-- in 1354.658942937851s\n",
      "eval pipeline \t-- in 6.7380900382995605s\n",
      "\t\t[*] fold 3 complete (test score of 6.8515689171603755) -- in 1361.397s\n",
      "\t\t[+] final score for params of 13.60324818601683 -- in 2484.216s\n",
      "\t\t[!] new best param configuration, so saving model to path\n",
      "\t\t\t[+] saved model to ../results/LinearSVR(13:54 on 3-12-2023).pkl\n",
      "\t[*] looking at hyperparameters {'C': 1.0, 'dual': 'auto'}\n",
      "split data \t-- in 1.2159347534179688e-05s\n",
      "made pipeline \t-- in 0.0001010894775390625s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   4.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total= 5.4min\n",
      "fit pipeline \t-- in 328.12718296051025s\n",
      "eval pipeline \t-- in 5.5861921310424805s\n",
      "\t\t[*] fold 1 complete (test score of 4.755031551385784) -- in 333.714s\n",
      "split data \t-- in 1.0013580322265625e-05s\n",
      "made pipeline \t-- in 0.00011205673217773438s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=12.5min\n",
      "fit pipeline \t-- in 761.6263680458069s\n",
      "eval pipeline \t-- in 5.644953012466431s\n",
      "\t\t[*] fold 2 complete (test score of 28.970044657679857) -- in 767.271s\n",
      "split data \t-- in 1.9073486328125e-06s\n",
      "made pipeline \t-- in 0.0001239776611328125s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=20.5min\n",
      "fit pipeline \t-- in 1245.1851398944855s\n",
      "eval pipeline \t-- in 5.78561806678772s\n",
      "\t\t[*] fold 3 complete (test score of 6.836381830138532) -- in 1250.971s\n",
      "\t\t[+] final score for params of 13.520486013068059 -- in 2351.957s\n",
      "\t\t[!] new best param configuration, so saving model to path\n",
      "\t\t\t[+] saved model to ../results/LinearSVR(13:54 on 3-12-2023).pkl\n",
      "\t[*] looking at hyperparameters {'C': 10.0, 'dual': 'auto'}\n",
      "split data \t-- in 5.0067901611328125e-06s\n",
      "made pipeline \t-- in 2.8133392333984375e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total= 5.8min\n",
      "fit pipeline \t-- in 353.29660987854004s\n",
      "eval pipeline \t-- in 5.739134073257446s\n",
      "\t\t[*] fold 1 complete (test score of 4.455386002093071) -- in 359.036s\n",
      "split data \t-- in 2.86102294921875e-06s\n",
      "made pipeline \t-- in 0.00010800361633300781s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   8.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=12.5min\n",
      "fit pipeline \t-- in 759.2692489624023s\n",
      "eval pipeline \t-- in 5.650629758834839s\n",
      "\t\t[*] fold 2 complete (test score of 30.058329713681175) -- in 764.92s\n",
      "split data \t-- in 5.0067901611328125e-06s\n",
      "made pipeline \t-- in 9.012222290039062e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=20.9min\n",
      "fit pipeline \t-- in 1269.294716835022s\n",
      "eval pipeline \t-- in 5.786826133728027s\n",
      "\t\t[*] fold 3 complete (test score of 6.812597098811412) -- in 1275.082s\n",
      "\t\t[+] final score for params of 13.775437604861885 -- in 2399.039s\n",
      "\t[*] looking at hyperparameters {'C': 100.0, 'dual': 'auto'}\n",
      "split data \t-- in 1.0967254638671875e-05s\n",
      "made pipeline \t-- in 5.507469177246094e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total= 5.8min\n",
      "fit pipeline \t-- in 350.72221088409424s\n",
      "eval pipeline \t-- in 5.439251184463501s\n",
      "\t\t[*] fold 1 complete (test score of 3.9362070485442735) -- in 356.162s\n",
      "split data \t-- in 7.152557373046875e-06s\n",
      "made pipeline \t-- in 0.00012493133544921875s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=12.8min\n",
      "fit pipeline \t-- in 778.549418926239s\n",
      "eval pipeline \t-- in 5.476837873458862s\n",
      "\t\t[*] fold 2 complete (test score of 28.689300528697444) -- in 784.026s\n",
      "split data \t-- in 9.5367431640625e-07s\n",
      "made pipeline \t-- in 9.775161743164062e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=21.2min\n",
      "fit pipeline \t-- in 1283.8037250041962s\n",
      "eval pipeline \t-- in 5.636337995529175s\n",
      "\t\t[*] fold 3 complete (test score of 7.145846830300674) -- in 1289.44s\n",
      "\t\t[+] final score for params of 13.257118135847465 -- in 2429.629s\n",
      "\t\t[!] new best param configuration, so saving model to path\n",
      "\t\t\t[+] saved model to ../results/LinearSVR(13:54 on 3-12-2023).pkl\n",
      "\t[+] best param configuration of {'dual': 'auto', 'C': 100.0} found with score 13.257118135847465\n",
      "\t[+] saved model to ../results/LinearSVR(13:54 on 3-12-2023).pkl\n"
     ]
    }
   ],
   "source": [
    "LINEARSVR_PARAM_GRID = ParameterGrid({\n",
    "    #'gamma': [1e-3, 1e-1, 1e1, 1e3, 1e5], #don't need gamma for linear\n",
    "    'C': [1e-1, 1e0, 1e1, 1e2],\n",
    "    'dual': [\"auto\"]\n",
    "})\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, LinearSVR, LINEARSVR_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] looking at model: LinearSVR(16:40 on 3-12-2023)\n",
      "\t[*] doing initial dataset splitting\n",
      "\t\t[+] fold 1\n",
      "\t\t[+] fold 2\n",
      "\t\t[+] fold 3\n",
      "\t[*] looking at hyperparameters {'C': 1000.0, 'dual': 'auto'}\n",
      "split data \t-- in 1.0967254638671875e-05s\n",
      "made pipeline \t-- in 4.601478576660156e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   4.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total= 5.9min\n",
      "fit pipeline \t-- in 357.7044150829315s\n",
      "eval pipeline \t-- in 5.449075937271118s\n",
      "\t\t[*] fold 1 complete (test score of 3.9504893728675814) -- in 363.154s\n",
      "split data \t-- in 1.0967254638671875e-05s\n",
      "made pipeline \t-- in 8.797645568847656e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   8.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=12.8min\n",
      "fit pipeline \t-- in 775.3218419551849s\n",
      "eval pipeline \t-- in 3.7379658222198486s\n",
      "\t\t[*] fold 2 complete (test score of 27.281421128763885) -- in 779.06s\n",
      "split data \t-- in 1.0013580322265625e-05s\n",
      "made pipeline \t-- in 9.226799011230469e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  10.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=20.2min\n",
      "fit pipeline \t-- in 1221.419251203537s\n",
      "eval pipeline \t-- in 5.466487884521484s\n",
      "\t\t[*] fold 3 complete (test score of 7.689797311311569) -- in 1226.886s\n",
      "\t\t[+] final score for params of 12.973902604314347 -- in 2369.101s\n",
      "\t\t[!] new best param configuration, so saving model to path\n",
      "\t\t\t[+] saved model to ../results/LinearSVR(16:40 on 3-12-2023).pkl\n",
      "\t[*] looking at hyperparameters {'C': 10000.0, 'dual': 'auto'}\n",
      "split data \t-- in 2.1457672119140625e-06s\n",
      "made pipeline \t-- in 2.5272369384765625e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total= 5.8min\n",
      "fit pipeline \t-- in 350.9046869277954s\n",
      "eval pipeline \t-- in 5.519390821456909s\n",
      "\t\t[*] fold 1 complete (test score of 3.9504893728675814) -- in 356.424s\n",
      "split data \t-- in 1.3113021850585938e-05s\n",
      "made pipeline \t-- in 0.00012183189392089844s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   8.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=13.1min\n",
      "fit pipeline \t-- in 793.3045499324799s\n",
      "eval pipeline \t-- in 5.405851125717163s\n",
      "\t\t[*] fold 2 complete (test score of 27.281421128763885) -- in 798.711s\n",
      "split data \t-- in 3.0994415283203125e-06s\n",
      "made pipeline \t-- in 8.511543273925781e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=20.6min\n",
      "fit pipeline \t-- in 1246.5140709877014s\n",
      "eval pipeline \t-- in 5.521338939666748s\n",
      "\t\t[*] fold 3 complete (test score of 7.722587294744636) -- in 1252.036s\n",
      "\t\t[+] final score for params of 12.984832598792034 -- in 2407.172s\n",
      "\t[*] looking at hyperparameters {'C': 100000.0, 'dual': 'auto'}\n",
      "split data \t-- in 1.9073486328125e-06s\n",
      "made pipeline \t-- in 4.696846008300781e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   3.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total= 5.8min\n",
      "fit pipeline \t-- in 350.0384418964386s\n",
      "eval pipeline \t-- in 3.7425267696380615s\n",
      "\t\t[*] fold 1 complete (test score of 3.9504893728675814) -- in 353.781s\n",
      "split data \t-- in 1.5735626220703125e-05s\n",
      "made pipeline \t-- in 9.107589721679688e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=   6.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=12.7min\n",
      "fit pipeline \t-- in 767.9597029685974s\n",
      "eval pipeline \t-- in 5.039690017700195s\n",
      "\t\t[*] fold 2 complete (test score of 27.281421128763885) -- in 773.0s\n",
      "split data \t-- in 1.0013580322265625e-05s\n",
      "made pipeline \t-- in 7.295608520507812e-05s\n",
      "[Pipeline] ........ (step 1 of 2) Processing preprocess, total=  11.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/alexanderportland/anaconda3/envs/data1030/lib/python3.11/site-packages/sklearn/svm/_base.py:1242: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 2) Processing model, total=21.2min\n",
      "fit pipeline \t-- in 1286.1262011528015s\n",
      "eval pipeline \t-- in 5.67920994758606s\n",
      "\t\t[*] fold 3 complete (test score of 7.722587294744636) -- in 1291.806s\n",
      "\t\t[+] final score for params of 12.984832598792034 -- in 2418.587s\n",
      "\t[+] best param configuration of {'dual': 'auto', 'C': 1000.0} found with score 12.973902604314347\n",
      "\t[+] saved model to ../results/LinearSVR(16:40 on 3-12-2023).pkl\n"
     ]
    }
   ],
   "source": [
    "LINEARSVR_PARAM_GRID = ParameterGrid({\n",
    "    #'gamma': [1e-3, 1e-1, 1e1, 1e3, 1e5], #don't need gamma for linear\n",
    "    'C': [1e3, 1e4, 1e5],\n",
    "    'dual': [\"auto\"]\n",
    "})\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, LinearSVR, LINEARSVR_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bca6cae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] looking at model: XGBRegressor(22:06 on 3-12-2023)\n",
      "\t[*] doing initial dataset splitting\n",
      "\t\t[+] fold 1\n",
      "\t\t[+] fold 2\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "\n",
    "XGB_PARAM_GRID = ParameterGrid({\n",
    "    \"learning_rate\": [0.03],\n",
    "    \"n_estimators\": [1000],\n",
    "    #\"early_stopping_rounds\": [50],\n",
    "    \"reg_alpha\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "    \"reg_lambda\": [0e0, 1e-2, 1e-1, 1e0, 1e1, 1e2],\n",
    "    #\"max_depth\": [1,3,10,30,100],\n",
    "    \"seed\": [14],\n",
    "    \"colsample_bytree\": [0.9],              \n",
    "    \"subsample\": [0.66]\n",
    "    })\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, xgboost.XGBRegressor, XGB_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e52c9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6df889",
   "metadata": {},
   "outputs": [],
   "source": [
    "RIDGE_PARAM_GRID = ParameterGrid({\n",
    "            'alpha': np.geomspace(0.01, 10000, 12), # no upper bound so the values are evenly spaced in log\n",
    "            })\n",
    "RIDGE_PARAM_GRID_SMALL = ParameterGrid({\n",
    "            'alpha': [0.1, 1, 10, 100], # no upper bound so the values are evenly spaced in log\n",
    "            })\n",
    "\n",
    "#MLPipe_TimeSeries_RMSE(X, y, preprocessor, Ridge, RIDGE_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc011ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ELASTIC_PARAM_GRID = {\n",
    "            'alpha': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000], # no upper bound so the values are evenly spaced in log\n",
    "            'l1_ratio': np.linspace(0.2, 1, 9)\n",
    "            }\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, ElasticNet, ELASTIC_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e816f0",
   "metadata": {},
   "source": [
    "### Training Non-Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "324cbe77",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_PARAM_GRID = ParameterGrid({\n",
    "            'max_depth': [1, 3, 4, 7, 10, 14, 21, 31], # no upper bound so the values are evenly spaced in log\n",
    "            'max_features': np.linspace(0.2, 1, 5)\n",
    "            })\n",
    "RF_PARAM_GRID_SMALL = ParameterGrid({\n",
    "            'max_depth': [1, 3, 7, 14, 31], # no upper bound so the values are evenly spaced in log\n",
    "            'max_features': np.linspace(0.2, 1, 3)\n",
    "            })\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, RandomForestRegressor, RF_PARAM_GRID)\n",
    "\n",
    "ELASTIC_PARAM_GRID = {\n",
    "            'alpha': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000], # no upper bound so the values are evenly spaced in log\n",
    "            'l1_ratio': np.linspace(0.2, 1, 9)\n",
    "            }\n",
    "\n",
    "MLPipe_TimeSeries_RMSE(X, y, preprocessor, ElasticNet, ELASTIC_PARAM_GRID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82921452",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93183abc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6324bb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5603d62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_partial = X_test.sample(np.floor((len(X_test) * 0.3)).astype(int))\n",
    "y_test_partial = y_test.loc[X_test_partial.index]\n",
    "y_test_partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "449f3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trains = []\n",
    "y_trains = []\n",
    "X_vals = []\n",
    "y_vals = []\n",
    "for i in range(1, 3 + 1):\n",
    "    train_portion = np.round(i * VAL_PORTION, 2)\n",
    "    div_0 = new_quarters[0]\n",
    "    div_1 = new_quarters[int(quarter_count * train_portion)]\n",
    "    div_2 = new_quarters[int(quarter_count * (train_portion + VAL_PORTION))]\n",
    "\n",
    "    X_trains.append(X[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "    y_trains.append(y[(div_0 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_1)])\n",
    "    X_vals.append(X[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])\n",
    "    y_vals.append(y[(div_1 <= X[\"TIME_PERIOD\"]) & (X[\"TIME_PERIOD\"] < div_2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f8a7ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57cca2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_best = np.argmin(param_scores)\n",
    "param_scores[i_best]\n",
    "param_grid[i_best]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929dfc9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ML_algo.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcc3dba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68176db2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b354b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(\"../results/Ridge(19:57 on 2-12-2023).pkl\")\n",
    "cfs = pd.DataFrame(model.named_steps[\"model\"].coef_)\n",
    "cfs.index = model.named_steps['preprocess'].get_feature_names_out()\n",
    "cfs[0].sort_values(ascending=False).head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b5da48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8420b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#old split checking\n",
    "def check_split_sizes(X, train, test, val):\n",
    "    fails = 0\n",
    "    print(\"[*] checking train test val split\")\n",
    "    train_set_qs = set(train[\"TIME_PERIOD\"])\n",
    "    test_set_qs = set(test[\"TIME_PERIOD\"])\n",
    "    val_set_qs = set(val[\"TIME_PERIOD\"])\n",
    "    \n",
    "    #check for TIME_PERIOD overlap\n",
    "    shared = (train_set_qs & test_set_qs) | (val_set_qs & test_set_qs) | (train_set_qs & val_set_qs)\n",
    "    if (len(shared) != 0):\n",
    "        warnings.warn('\\t[-] overlap between train, test, or val time_periods')\n",
    "        fails+=1\n",
    "    else:\n",
    "        print(\"\\t[+] no overlap between train, test, or val TIME_PERIODS\")\n",
    "        \n",
    "    #check for a fairly even 60/20/20 split\n",
    "    NAMES = ['train', 'test ', 'val  ']\n",
    "    TARGETS = [0.6, 0.2, 0.2]\n",
    "    ALLOWED_FRACTION_ERROR = 0.02\n",
    "    sizes = [len(train) / len(X), len(test) / len(X), len(val) / len(X)]\n",
    "    for i in range(0, 3):\n",
    "        if (np.abs(sizes[i] - TARGETS[i]) < ALLOWED_FRACTION_ERROR):\n",
    "            print(\"\\t[+] \" + str(NAMES[i]) + \" is \" + str(np.round(sizes[i], 3)) + \" of datapoints which is within bounds of its \" + str(TARGETS[i]) + \" target\")\n",
    "        else:\n",
    "            warnings.warn(\"\\t[-] \" + str(NAMES[i]) + \" is \" + str(np.round(sizes[i], 3)) + \" of datapoints which is out of bounds\")\n",
    "            fails+=1\n",
    "\n",
    "    if (fails == 0):\n",
    "        print(\"\\t[+] \\x1b[42mPASSED ALL\\x1b[0m train test val split tests\")\n",
    "    else:\n",
    "        print(\"\\t[?] \\033[91mFAILED \" + str(fails) + \"\\033[0m train test val split tests\")\n",
    "        \n",
    "\n",
    "#check_split_sizes(X, X_train, X_test, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8d982fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c0f57a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b72b064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fdadb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a063c616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d30ce7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25946758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49b8071",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d532059",
   "metadata": {},
   "source": [
    "## 3. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "650c131d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#****************************************************feature scaling********************************************************\n",
    "\n",
    "ordinal_ftrs = ['age', 'TIME_PERIOD']\n",
    "ordinal_cats = [['UNK','Y_LT14','Y14-17','Y18-34','Y35-64','Y_GE65'], quarters]\n",
    "                                                                     #^^i'm using quarters not new_quarters here so that\n",
    "                                                                     #  the model can still tell where in history this q is\n",
    "onehot_ftrs = ['citizen', 'geo', 'sex']\n",
    "#onehot_ftrs = ['geo', 'sex']\n",
    "minmax_ftrs = []\n",
    "std_ftrs = [a for a in X.columns.to_list() if 'TOTAL' in a]\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('ord', OrdinalEncoder(categories = ordinal_cats), ordinal_ftrs),\n",
    "        ('onehot', OneHotEncoder(sparse_output=False,handle_unknown='ignore'), onehot_ftrs),\n",
    "        ('minmax', MinMaxScaler(), minmax_ftrs),\n",
    "        ('std', StandardScaler(), std_ftrs)])\n",
    "\n",
    "#clf = Pipeline(steps=[('preprocessor', preprocessor)]) # for now we only preprocess \n",
    "                                                       # later on we will add other steps here\n",
    "\n",
    "#X_train_prep = clf.fit_transform(X_train)\n",
    "#X_val_prep = clf.transform(X_val)\n",
    "#X_test_prep = clf.transform(X_test)\n",
    "\n",
    "#print(X_train.shape)\n",
    "#print(X_train_prep.shape)\n",
    "#print(X_train_prep)\n",
    "#X_prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d55328c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba1c98e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab34edd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
